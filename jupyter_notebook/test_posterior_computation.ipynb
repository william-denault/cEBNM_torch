{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "from scipy.stats import norm\n",
    "from scipy.stats import truncnorm\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoselect_scales_mix_norm(betahat, sebetahat, max_class=None, mult=2):\n",
    "    sigmaamin = np.min(sebetahat) / 10\n",
    "    if np.all(betahat**2 < sigmaamin**2):  # Fix the typo and ensure logical comparison\n",
    "        sigmaamax = 8 * sigmaamin\n",
    "    else:\n",
    "        sigmaamax = 2*np.sqrt(np.max(betahat**2 - sebetahat**2))\n",
    "    \n",
    "    if mult == 0:\n",
    "        out = np.array([0, sigmaamax / 2])\n",
    "    else:\n",
    "        npoint = math.ceil(math.log2(sigmaamax / sigmaamin) / math.log2(mult))\n",
    "\n",
    "        # Generate the sequence (-npoint):0 using np.arange\n",
    "        sequence = np.arange(-npoint, 1)\n",
    "\n",
    "        # Calculate the output\n",
    "        out = np.concatenate(([0], (1/mult) ** (-sequence) * sigmaamax))\n",
    "        if max_class!=None:\n",
    "            # Check if the length of out is equal to max_class\n",
    "            if len(out) != max_class:\n",
    "            # Generate a sequence from min(out) to max(out) with length max_class\n",
    "                out = np.linspace(np.min(out), np.max(out), num=max_class)\n",
    "        \n",
    "    \n",
    "    return out\n",
    "     \n",
    "def autoselect_scales_mix_exp(betahat, sebetahat, max_class=None , mult=1.5,tt=1.5):\n",
    "    sigmaamin = np.min(sebetahat) / 10\n",
    "    if np.all(betahat**2 < sigmaamin**2):  # Fix the typo and ensure logical comparison\n",
    "        sigmaamax = 8 * sigmaamin\n",
    "    else:\n",
    "        sigmaamax = tt*np.sqrt(np.max(betahat**2  ))\n",
    "    \n",
    "    if mult == 0:\n",
    "        out = np.array([0, sigmaamax / 2])\n",
    "    else:\n",
    "        npoint = math.ceil(math.log2(sigmaamax / sigmaamin) / math.log2(mult))\n",
    "\n",
    "        # Generate the sequence (-npoint):0 using np.arange\n",
    "        sequence = np.arange(-npoint, 1)\n",
    "\n",
    "        # Calculate the output\n",
    "        out = np.concatenate(([0], (1/mult) ** (-sequence) * sigmaamax))\n",
    "        if max_class!=None:\n",
    "            # Check if the length of out is equal to max_class\n",
    "            if len(out) != max_class:\n",
    "            # Generate a sequence from min(out) to max(out) with length max_class\n",
    "                out = np.linspace(np.min(out), np.max(out), num=max_class)\n",
    "                if(out[2] <1e-2 ):\n",
    "                 out[2: ] <- out[2: ] +1e-2\n",
    "         \n",
    "    \n",
    "    return out\n",
    "\n",
    "    \n",
    "class PosteriorMeanExp:\n",
    "    def __init__(self, post_mean, post_mean2, post_sd):\n",
    "        self.post_mean = post_mean\n",
    "        self.post_mean2 = post_mean2\n",
    "        self.post_sd = post_sd\n",
    "\n",
    "def posterior_mean_exp(betahat, sebetahat, log_pi, scale):\n",
    "    assignment = np.exp(log_pi)\n",
    "    assignment = assignment / assignment.sum(axis=1, keepdims=True)\n",
    "    mu = 0\n",
    "    post_assign = np.zeros((betahat.shape[0], scale.shape[0]))\n",
    "    \n",
    "    for i in range(betahat.shape[0]):\n",
    "        post_assign[i,] = wpost_exp(x=betahat[i],\n",
    "                                    s=sebetahat[i], \n",
    "                                    w=assignment[i,],\n",
    "                                    scale=scale) \n",
    "    \n",
    "    post_mean = np.zeros(betahat.shape[0])\n",
    "    post_mean2 = np.zeros(betahat.shape[0])\n",
    "\n",
    "    for i in range(post_mean.shape[0]):\n",
    "        post_mean[i] = sum(post_assign[i, 1:] * my_etruncnorm(0,\n",
    "                                                              np.inf,\n",
    "                                                              betahat[i] - sebetahat[i]**2 * (1/scale[1:]), \n",
    "                                                              sebetahat[i]))\n",
    "        post_mean2[i] = sum(post_assign[i, 1:] * my_e2truncnorm(0,\n",
    "                                                                99999, #some weird warning for inf so just use something large enough for b\n",
    "                                                                betahat[i] - sebetahat[i]**2 * (1/scale[1:]), \n",
    "                                                                sebetahat[i]))\n",
    "        post_mean2[i] = max(post_mean[i], post_mean2[i])\n",
    "    \n",
    "    if np.any(np.isinf(sebetahat)):\n",
    "        inf_indices = np.isinf(sebetahat)\n",
    "        a = 1/scale[1:]\n",
    "        # Equivalent of `post$mean[is.infinite(s)]` \n",
    "        post_mean[inf_indices] = np.sum(post_assign[inf_indices, 1:] / a, axis=1)\n",
    "\n",
    "        # Equivalent of `post$mean2[is.infinite(s)]`\n",
    "        post_mean2[inf_indices] = np.sum(2 * post_assign[inf_indices, 1:] / a**2, axis=1)\n",
    "\n",
    "    # Calculate `post_sd`\n",
    "    post_sd = np.sqrt(np.maximum(0, post_mean2 - post_mean**2))\n",
    "\n",
    "    # Update `post_mean2` and `post_mean`\n",
    "    post_mean2 = post_mean2 + mu**2 + 2 * mu * post_mean\n",
    "    post_mean = post_mean + mu\n",
    "\n",
    "    # Return the results as an instance of PosteriorMeanExpResult\n",
    "    return PosteriorMeanExp(post_mean, post_mean2, post_sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.03827328 0.07654655 0.15309311 0.30618622 0.61237244\n",
      " 1.22474487 2.44948974 4.89897949 9.79795897]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "betahat=  np.array([1,2,3,4,5])\n",
    "sebetahat=np.array([1,0.4,5,1,1])\n",
    "scale = autoselect_scales_mix_norm ( np.array([1,2,3,4,5]),  np.array([1,0.4,5,1,1]))\n",
    "location = 0* scale\n",
    "n=betahat.shape[0]\n",
    "p= scale.shape[0]\n",
    " \n",
    "log_pi =  np.log( np.full( (n, p), 1/scale.shape[0]))\n",
    "print(scale)\n",
    "print(location)\n",
    "#res = posterior_mean_exp(betahat, sebetahat, log_pi, scale)\n",
    "#print(res.post_mean)\n",
    "#print(res.post_mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n"
     ]
    }
   ],
   "source": [
    "#compute gaussian likelihood\n",
    "\n",
    "convolved_logpdf.normal <- function(  betahat, sebetahat, location, scale):\n",
    "  # Calculate the standard deviation\n",
    "    sd = np.sqrt(se**2 +  scale**2)\n",
    "    \n",
    "    # Calculate the log probability density\n",
    "    logp = norm.logpdf(betahat, loc= location, scale=sd)\n",
    "    \n",
    "    # Clamp the log probabilities to the range [-1e4, 1e4]\n",
    "    logp = np.clip(logp, -1e4, 1e4)\n",
    "    \n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writing wpost_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "[0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "[0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "[3.53987758e-06 6.61493885e-06 1.06391083e-05 2.86976960e-05\n",
      " 1.69165759e-04 1.40776600e-03 8.91255655e-03 3.45101678e-02\n",
      " 8.34205613e-02 1.38160703e-01 1.72844260e-01 1.77093219e-01\n",
      " 1.57939387e-01 1.28091688e-01 9.74010338e-02]\n"
     ]
    }
   ],
   "source": [
    "w=assignment\n",
    "print(w)\n",
    "wpost_exp ( x, s, w, scale)\n",
    "temp_array =   np.zeros ( (betahat.shape[0], scale.shape[0]))\n",
    "i=1\n",
    "temp_array[i,] = wpost_exp ( x=betahat[i], s=sebetahat[i], w=w, scale=scale) \n",
    "print(temp_array[i,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res.post_mean should be equal to [0.4836384 1.8932834 1.0567097 3.5700976 4.6637965]\n",
    "res.post_mean2 should be equal to [ 0.5967422  3.7537202  4.3433782 13.8929910 22.8110722]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
