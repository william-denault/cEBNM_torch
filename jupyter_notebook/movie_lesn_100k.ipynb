{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "\n",
    "# Step 1: Load MovieLens 100k data from file or URL\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.data'\n",
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(url, sep='\\t', names=column_names)\n",
    "\n",
    "# Create a pivot table (user-item matrix) for ratings\n",
    "ratings_matrix = df.pivot(index='user_id', columns='item_id', values='rating')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import svds\n",
    " \n",
    "# Step 3: Identify non-NA entries in the ratings matrix\n",
    "non_na_mask = ratings_matrix.notna()\n",
    "\n",
    "# Convert mask to a list of non-NA (user, item) pairs\n",
    "non_na_indices = np.argwhere(non_na_mask.values)  # Get (row, col) indices of non-NA values\n",
    "\n",
    "# Randomly select 20% of non-NA entries to introduce missing data\n",
    "n_remove = int(0.2 * len(non_na_indices))  # 20% of available data\n",
    "remove_indices = np.random.choice(np.arange(len(non_na_indices)), size=n_remove, replace=False)\n",
    "\n",
    "# Save the original values that will be removed for later evaluation\n",
    "original_values = ratings_matrix.copy()\n",
    "\n",
    "# Step 4: Introduce missing values\n",
    "ratings_matrix_masked = ratings_matrix.copy()\n",
    "\n",
    "# Set the selected 20% of data points to NaN\n",
    "for index in remove_indices:\n",
    "    row, col = non_na_indices[index]  # Get the (row, col) pair\n",
    "    ratings_matrix_masked.iloc[row, col] = np.nan  # Set the value at that position to NaN\n",
    "\n",
    "# Step 5: Fill the missing values with 0 for SVD input (other methods can be used here)\n",
    "R_filled = ratings_matrix_masked.fillna(0).values\n",
    "\n",
    "# Step 6: Apply SVD (Singular Value Decomposition)\n",
    "# Decompose the matrix using SVD\n",
    "U, sigma, Vt = svds(R_filled, k=50)  # Using 50 latent factors\n",
    "sigma = np.diag(sigma)  # Convert sigma (1D array) to a diagonal matrix\n",
    "\n",
    "# Reconstruct the matrix using the decomposed matrices\n",
    "R_predicted = np.dot(np.dot(U, sigma), Vt)\n",
    "\n",
    "# Step 7: Evaluate performance of the SVD model\n",
    "# Create a DataFrame for the predicted ratings\n",
    "imputed_ratings = pd.DataFrame(R_predicted, columns=ratings_matrix.columns, index=ratings_matrix.index)\n",
    "\n",
    "# Calculate RMSE on the originally removed 20% of the data\n",
    "true_values = original_values.iloc[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "predicted_values = imputed_ratings.iloc[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values shape: (20000,)\n",
      "Predicted values shape: (20000,)\n",
      "RMSE for the SVD-based prediction: 2.879682599724702\n"
     ]
    }
   ],
   "source": [
    "# Extract the values from the original matrix and imputed matrix for comparison\n",
    "true_values = original_values.values[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "predicted_values = imputed_ratings.values[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "\n",
    "# Check if their shapes match\n",
    "print(f\"True values shape: {true_values.shape}\")\n",
    "print(f\"Predicted values shape: {predicted_values.shape}\")\n",
    "\n",
    "# Calculate RMSE if shapes match\n",
    "if true_values.shape == predicted_values.shape:\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "    print(f'RMSE for the SVD-based prediction: {rmse}')\n",
    "else:\n",
    "    print(\"Error: Shape mismatch between true values and predicted values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows Ã— 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                              ...   \n",
       "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   NaN   5.0   3.0  ...   \n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   \n",
       "940       NaN   NaN   NaN   2.0   NaN   NaN   4.0   NaN   3.0   NaN  ...   \n",
       "941       5.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   \n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "943       NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user_id                                                              \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "940       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "941       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "943       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix_masked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fancyimpute import IterativeSVD\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the path to utils.py\n",
    "sys.path.append(r\"c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\")\n",
    "from cEBMF import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycebmf= cEBMF(data= np.array(ratings_matrix_masked), K=12,\n",
    "               prior_L = \"exp\",\n",
    "               prior_F = \"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The array contains missing values (NaN), generate initialization using iterive svd.\n",
      "[IterativeSVD] Iter 1: observed MAE=2.680426\n",
      "[IterativeSVD] Iter 2: observed MAE=2.144061\n",
      "[IterativeSVD] Iter 3: observed MAE=1.732412\n",
      "[IterativeSVD] Iter 4: observed MAE=1.416035\n",
      "[IterativeSVD] Iter 5: observed MAE=1.218222\n",
      "[IterativeSVD] Iter 6: observed MAE=1.097939\n",
      "[IterativeSVD] Iter 7: observed MAE=1.016063\n",
      "[IterativeSVD] Iter 8: observed MAE=0.956949\n",
      "[IterativeSVD] Iter 9: observed MAE=0.912220\n",
      "[IterativeSVD] Iter 10: observed MAE=0.876983\n",
      "[IterativeSVD] Iter 11: observed MAE=0.848586\n",
      "[IterativeSVD] Iter 12: observed MAE=0.825208\n",
      "[IterativeSVD] Iter 13: observed MAE=0.805537\n",
      "[IterativeSVD] Iter 14: observed MAE=0.788798\n",
      "[IterativeSVD] Iter 15: observed MAE=0.774378\n",
      "[IterativeSVD] Iter 16: observed MAE=0.761873\n",
      "[IterativeSVD] Iter 17: observed MAE=0.750850\n",
      "[IterativeSVD] Iter 18: observed MAE=0.741076\n",
      "[IterativeSVD] Iter 19: observed MAE=0.732327\n",
      "[IterativeSVD] Iter 20: observed MAE=0.724428\n",
      "[IterativeSVD] Iter 21: observed MAE=0.717270\n",
      "[IterativeSVD] Iter 22: observed MAE=0.710744\n",
      "[IterativeSVD] Iter 23: observed MAE=0.704759\n",
      "[IterativeSVD] Iter 24: observed MAE=0.699255\n",
      "[IterativeSVD] Iter 25: observed MAE=0.694166\n",
      "[IterativeSVD] Iter 26: observed MAE=0.689453\n",
      "[IterativeSVD] Iter 27: observed MAE=0.685081\n",
      "[IterativeSVD] Iter 28: observed MAE=0.681004\n",
      "[IterativeSVD] Iter 29: observed MAE=0.677187\n",
      "[IterativeSVD] Iter 30: observed MAE=0.673606\n",
      "[IterativeSVD] Iter 31: observed MAE=0.670245\n",
      "[IterativeSVD] Iter 32: observed MAE=0.667075\n",
      "[IterativeSVD] Iter 33: observed MAE=0.664078\n",
      "[IterativeSVD] Iter 34: observed MAE=0.661243\n",
      "[IterativeSVD] Iter 35: observed MAE=0.658552\n",
      "[IterativeSVD] Iter 36: observed MAE=0.655998\n",
      "[IterativeSVD] Iter 37: observed MAE=0.653565\n",
      "[IterativeSVD] Iter 38: observed MAE=0.651248\n",
      "[IterativeSVD] Iter 39: observed MAE=0.649040\n",
      "[IterativeSVD] Iter 40: observed MAE=0.646932\n",
      "[IterativeSVD] Iter 41: observed MAE=0.644909\n",
      "[IterativeSVD] Iter 42: observed MAE=0.642966\n",
      "[IterativeSVD] Iter 43: observed MAE=0.641098\n",
      "[IterativeSVD] Iter 44: observed MAE=0.639303\n",
      "[IterativeSVD] Iter 45: observed MAE=0.637574\n",
      "[IterativeSVD] Iter 46: observed MAE=0.635908\n",
      "[IterativeSVD] Iter 47: observed MAE=0.634301\n",
      "[IterativeSVD] Iter 48: observed MAE=0.632748\n",
      "[IterativeSVD] Iter 49: observed MAE=0.631248\n",
      "[IterativeSVD] Iter 50: observed MAE=0.629797\n",
      "[IterativeSVD] Iter 51: observed MAE=0.628396\n",
      "[IterativeSVD] Iter 52: observed MAE=0.627039\n",
      "[IterativeSVD] Iter 53: observed MAE=0.625729\n",
      "[IterativeSVD] Iter 54: observed MAE=0.624461\n",
      "[IterativeSVD] Iter 55: observed MAE=0.623232\n",
      "[IterativeSVD] Iter 56: observed MAE=0.622036\n",
      "[IterativeSVD] Iter 57: observed MAE=0.620873\n",
      "[IterativeSVD] Iter 58: observed MAE=0.619741\n",
      "[IterativeSVD] Iter 59: observed MAE=0.618642\n",
      "[IterativeSVD] Iter 60: observed MAE=0.617573\n",
      "[IterativeSVD] Iter 61: observed MAE=0.616533\n",
      "[IterativeSVD] Iter 62: observed MAE=0.615521\n",
      "[IterativeSVD] Iter 63: observed MAE=0.614538\n",
      "[IterativeSVD] Iter 64: observed MAE=0.613580\n",
      "[IterativeSVD] Iter 65: observed MAE=0.612646\n",
      "[IterativeSVD] Iter 66: observed MAE=0.611734\n",
      "[IterativeSVD] Iter 67: observed MAE=0.610844\n",
      "[IterativeSVD] Iter 68: observed MAE=0.609972\n",
      "[IterativeSVD] Iter 69: observed MAE=0.609120\n",
      "[IterativeSVD] Iter 70: observed MAE=0.608286\n",
      "[IterativeSVD] Iter 71: observed MAE=0.607472\n",
      "[IterativeSVD] Iter 72: observed MAE=0.606677\n",
      "[IterativeSVD] Iter 73: observed MAE=0.605898\n",
      "[IterativeSVD] Iter 74: observed MAE=0.605135\n",
      "[IterativeSVD] Iter 75: observed MAE=0.604387\n",
      "[IterativeSVD] Iter 76: observed MAE=0.603656\n",
      "[IterativeSVD] Iter 77: observed MAE=0.602939\n",
      "[IterativeSVD] Iter 78: observed MAE=0.602236\n",
      "[IterativeSVD] Iter 79: observed MAE=0.601545\n",
      "[IterativeSVD] Iter 80: observed MAE=0.600868\n",
      "[IterativeSVD] Iter 81: observed MAE=0.600203\n",
      "[IterativeSVD] Iter 82: observed MAE=0.599553\n",
      "[IterativeSVD] Iter 83: observed MAE=0.598915\n",
      "[IterativeSVD] Iter 84: observed MAE=0.598288\n",
      "[  4.91673922 -35.63584147 -15.45213977 -32.10597949  22.57976538\n",
      "  14.2484246   19.44980879  -6.86137164   0.80242067  16.61837958\n",
      "  -1.17328901  -2.40541898   8.06400434  21.37866754 -33.11474402\n",
      "  23.61129953 -18.45322807  16.0296572   -3.90960458  -4.64938549\n",
      "  -3.3863945   11.04531379  17.8859608    0.49550177  17.14753199\n",
      " -30.67808975 -28.01196004   4.18773877  -3.33112153  -9.12633404\n",
      "  16.6857288  -31.07122276 -35.65606549 -32.03391864 -31.06949701\n",
      " -42.77132136  -6.04253429  18.42517711 -26.84828652 -31.77470086\n",
      "  16.85164618  14.30269293   0.35392392  12.87734751 -25.89634738\n",
      " -43.93365661 -29.36606598   4.57760734   9.21323027 -21.97535448\n",
      "  -0.47437695  -4.71441469  -8.12718446 -40.09109959  -9.20227467\n",
      "   2.89971041 -28.97128066  -0.81672809  11.20511268  24.05305823\n",
      " -30.70494973  11.55931392 -25.28069721  14.55139267  15.1780139\n",
      " -31.0608199  -19.7011321  -11.4721296  -14.55765554  15.16011519\n",
      "   9.18639581  21.69660968  16.97483769 -37.79136156  -7.80243956\n",
      "   0.5966844   21.95351923 -36.15669962 -29.621916    -0.84256869\n",
      "  -8.7873206    9.93453566   7.14457204   9.52699096  11.617389\n",
      " -24.93414244  10.90143259 -35.83540292 -19.00945239  12.05068283\n",
      "  -1.75329507   8.53202888 -17.66128966  20.11968951  10.7497443\n",
      "  16.60936265  16.59617289  10.80393447 -19.04506945 -28.65732957\n",
      " -30.75958247   6.95679609 -19.36305108 -28.06231832 -27.69323638\n",
      "  13.27214618 -23.41012415 -20.12718209  -3.88978234  -5.80826902\n",
      " -28.49855142 -39.02484266 -56.59581872  14.77517322   5.04992035\n",
      "  -5.2196044  -22.82252881  15.88301625  -9.47577888 -26.41847438\n",
      "   6.57204936  30.48309695  18.96051676   6.2452472    6.27930493\n",
      " -30.88661101 -21.32350863  20.3666805  -20.96224139  -8.94101075\n",
      " -30.00965715  11.01624148 -28.27804543 -31.41114333  -1.54080897\n",
      "  -2.49985073 -32.34323333  22.54061021 -41.53269474 -33.06271583\n",
      " -41.69904552  -9.06383651 -36.15517276   1.15597311  -5.76592621\n",
      " -33.09417466 -30.9563746   22.59339628 -25.18777161 -30.17568775\n",
      "  16.5446781    7.09926405  -5.64974141  21.97424619 -22.41780136\n",
      "  21.01490394 -42.79041872  20.33741566 -32.10958499  13.64925881\n",
      " -14.3605888  -12.35152323 -11.78554862 -46.15694419 -11.41497956\n",
      " -35.2817932   26.30121119 -28.55201673  -4.2990152  -39.73917798\n",
      " -26.79227288  22.25652376 -43.63547133  -4.00287878   9.92402027\n",
      " -34.72897613  -1.42926698   2.31759504 -32.66869596   9.75812872\n",
      " -17.17974603   5.08812541   7.827222     9.48966602   6.94160691\n",
      " -13.48171708  11.75052056   9.39548049  16.27690746 -38.27934088\n",
      " -19.62198819 -33.73255024   7.76989624  21.76674207  -0.59960616\n",
      "  10.49882009  -8.79375199   7.18523961 -25.00689535   9.0281857\n",
      "   5.11144939  12.56288309 -38.69072555  -7.10129452 -25.92298569\n",
      " -27.4809673    0.86348921  18.65202668 -33.27023125  12.35130477\n",
      "  -7.35459868  20.53883491  17.9583785    8.32313598  13.82856645\n",
      "   2.49151445  -2.49330831  13.44271954  -3.08919057 -30.43209182\n",
      "  -2.93428152   0.70057747 -12.59445398  -6.57687069  22.83498188\n",
      " -10.6626262  -23.37036677  -1.5271972  -23.76823112   6.24236286\n",
      " -30.32564809  14.46524284   5.85841404  13.55114792  15.12333062\n",
      "   1.71746809  20.36342685 -31.13239766  32.04593111 -33.66305765\n",
      " -30.86682383 -43.14644742  10.44390537   0.58008948 -21.13621362\n",
      "   7.99552571  -8.14530556  -6.3558461    5.70119204  -3.96591118\n",
      "  -4.60185551 -29.21084339   6.67841236   8.53262984 -23.68012902\n",
      " -11.48332311 -16.59975773 -37.11301191  -0.32753583 -43.18246219\n",
      " -53.24022978   2.66885265  24.77205883  25.08677103 -38.07655555\n",
      " -19.00082475  19.84834803   6.21492584  20.61279984  -4.87014605\n",
      "   8.48982327  12.68839948 -23.67827632   0.38011717  13.54426558\n",
      "   8.39051897 -36.0316856   -8.65850879   7.29826346   2.14626988\n",
      " -32.09863781 -27.04809326  11.70007596 -32.76688825 -18.99226741\n",
      " -10.40344473  -8.12928018  -5.4215197  -20.74652568  12.15207228\n",
      "  16.96809043  17.5368941   18.35543835 -29.77949149  31.08150425\n",
      "  -2.99983607   2.84630859  13.23459649   9.69287537 -54.34394605\n",
      "   4.09300435 -21.71244782  12.25637864 -34.24917088  10.76344165\n",
      " -30.62200232  14.14703681  14.43370711 -36.41038698 -27.16054394\n",
      "   2.37662993  21.1376283   14.49911    -20.95531647  14.5289541\n",
      "  11.70076546 -39.41686818  11.42885837 -34.54206742  -3.94890453\n",
      "  19.99204055   9.91820995  -3.21100647 -58.81943299  32.57640636\n",
      "  31.70273468   7.88370555   2.31593547  -8.71165779  15.09377292\n",
      "   5.48092059 -15.13677215  -6.90929497   1.87386893 -34.52664984\n",
      "   2.3048168    6.63823171  20.93477628  20.94507316  17.93399948\n",
      " -41.50884573  18.80207699  17.61543817   7.47407966   0.7406331\n",
      "   0.29301468  -7.29922472 -41.06889768 -20.47841401  14.54036872\n",
      " -41.23685527   7.18079099 -28.94132493   6.66953514 -41.67243861\n",
      " -32.34078965 -46.95676332  10.2943243  -29.41598264   5.49203389\n",
      "  25.59727906 -37.23934283   3.83389911 -41.11986283 -36.41034982\n",
      "  16.72006982 -14.29232408 -13.63379996 -26.81051264  17.43473859\n",
      "   7.36053365 -12.12952268  13.89803833   1.64754945   1.46505033\n",
      "   0.95238664  -6.44594091   7.05181912  19.09067288   3.90897643\n",
      "   9.79815084  18.3622086   20.77738997 -38.90867884  18.67493158\n",
      " -28.02127012  15.28822149 -21.36794956  20.0312972  -38.436541\n",
      "  11.64357791   5.03990762  -2.14780711  10.57287541   2.32934195\n",
      " -37.03263524  11.05634286  20.65308823   1.93255901 -29.52852831\n",
      "  12.58361648   2.3700635  -29.72180297 -20.18291191  -4.96931429\n",
      "  23.45260516  13.56359069 -30.89161184   6.37833106 -26.16001133\n",
      "  10.22563706   6.48635178 -35.03067032 -21.44343579 -10.24167616\n",
      "   1.62483899  12.93703844 -20.17374125   9.82299019   6.22727301\n",
      "   1.50013843  -3.55204912 -41.18363366 -14.31371723  -3.91380038\n",
      "  15.9236483  -49.68794817 -46.25129007  10.4177389    4.26888408\n",
      " -30.36799827 -38.80669379   0.7010392  -32.95274012  -2.35839736\n",
      "   0.69768709  30.08624035 -35.49988955 -35.25200641 -19.07918665\n",
      " -31.23507018   2.98618029 -17.01134417 -32.3276854    3.30721953\n",
      " -28.23433487   4.53093104 -22.71582833  -6.85102871   5.31057754\n",
      " -40.80316722   9.98779763  -2.40874514  -8.13283632   1.61784365\n",
      "   9.51145781  17.42100565   0.71909838 -21.33011869 -33.42531598\n",
      " -15.49740144 -22.39357097 -34.30678008 -18.26681791  12.27986358\n",
      " -29.36346376 -27.27034751  18.79248308  27.64261191 -36.07017412\n",
      "   0.29373351  -3.06349566 -29.79994767  11.00938235 -14.13468384\n",
      "   5.83753338  -5.56754972   6.79855818  10.45648715   5.40154687\n",
      "  16.94791555 -39.57385291  -1.36763147   8.07977235 -28.77052002\n",
      " -35.34217436   4.12229668  10.60287123 -41.52699073 -19.4077706\n",
      "   9.89828259  12.73922657  -3.82731413  -2.17271744  23.49954323\n",
      "  20.455749     2.24361399  11.55998217  -0.65087444  11.84085486\n",
      " -41.70875209 -33.1150105   -3.6196564    8.57822957   4.28060736\n",
      "  13.70835525 -62.42935942  26.591897    -8.84399745 -30.36942258\n",
      " -42.73424888   5.62759635 -23.59550354   4.11074736 -34.35198502\n",
      "   6.04116562 -30.06633603 -29.07373298 -37.31187708 -33.05166484\n",
      "  -3.31011789  33.00304702  14.39317784  -3.23701363 -31.49988161\n",
      " -32.96427525  18.40641076   8.50168439 -39.49314203   1.29492258\n",
      " -28.01450997  -2.76531562  -1.6795836  -50.61896457  19.15249111\n",
      "  28.12771822  10.17296638  12.0025312   21.18475423 -40.38778313\n",
      "  18.31981174  13.34760997  15.62981403 -27.25673155   8.10255354\n",
      " -12.43005053 -30.74428433 -12.42821032 -28.35702757 -41.7748271\n",
      "  -8.39525402 -39.19660573  20.78091736   1.22708469  -5.70522782\n",
      "   9.73157549 -19.69631756 -22.35071944   5.88600205  -5.04839341\n",
      "  10.64484942  23.05977269  -0.49155128 -34.69371305  23.4031077\n",
      "  15.55666755  20.92121948  12.17479611 -27.80332128 -23.13849431\n",
      "  13.37918423 -23.43672554  16.34129632 -28.61476046   8.91002857\n",
      " -11.42667383  10.93450745 -29.34233013   4.99409675 -37.06531717\n",
      " -18.94967506 -28.81432348  19.85627786  -4.64580277   2.82443335\n",
      "  -6.30727722 -34.94056918   3.48504848 -36.04013908 -23.81551675\n",
      "  15.48889149   5.16690733   4.29861043  -6.08134838 -37.10653357\n",
      " -35.04880117 -43.30379657 -34.89698022 -51.03867276   9.61452317\n",
      "  21.85934763 -34.85344997  -3.75158775   4.20189664  -0.98140201\n",
      "   0.6874857    8.99824429  12.32014777 -32.23974341  13.41898311\n",
      " -39.20347133  -7.09545183   3.63444364 -22.77747747  17.4900201\n",
      " -39.11214412  21.52314506   4.86985397 -15.82536878   2.16351385\n",
      "   5.3196769   14.08630406  14.79467583 -42.73995093  10.24041329\n",
      " -14.84925049  14.43565623 -49.55823122  -4.88023137 -22.42540925\n",
      " -25.93681267  19.47758635  -0.70844421 -39.85013633 -34.87534068\n",
      " -32.01675731 -37.78200303   7.13215951  18.4368895   -3.20186813\n",
      "  10.27262942  -0.65451768  22.50801817 -47.17000984  27.87434936\n",
      " -30.09452892  10.46898701  16.65288123 -26.41113515  18.44839949\n",
      " -20.9330265  -15.17263294  -4.52634169   3.1434227    0.32821068\n",
      " -19.72509143 -20.30269065  13.09917584  13.84303481   4.18312979\n",
      "  16.23315173 -25.81336699 -18.35541002  24.38455198  -5.30234227\n",
      "   7.09769178  10.57783893 -27.22045972  13.27055897  23.0189469\n",
      "   2.99380281 -33.27408628 -23.3468332  -35.00368103  11.90373037\n",
      " -10.03925848 -33.94239471 -22.56297599   2.4151372   -4.58630214\n",
      " -24.51672774   0.2642933    6.60402805  11.85858285 -20.34482284\n",
      "  13.55964354 -30.05444796 -46.28194704 -30.34828547  12.36834182\n",
      "  15.87272647  -7.04483221  12.40516618  22.83345023 -28.93396668\n",
      "  -0.31735067 -44.91171003   4.54452897 -22.44245317  -1.26878504\n",
      " -33.28169719 -11.90500924 -28.44818782  16.28256595  -8.01032417\n",
      " -27.11293802   1.17784245 -42.31401535  -1.24684119   6.88848067\n",
      "   9.3606192    0.85579675 -25.57032569 -29.72613491  -1.70803493\n",
      "  16.91137073 -51.43517554 -38.91306203   9.58006393 -35.3347912\n",
      " -13.08676589 -33.98483146  -4.9419695  -29.87736331 -44.47572992\n",
      " -38.4739623    4.74747306 -30.98189729 -28.32309861 -28.69522819\n",
      "  15.5565123  -33.55748851 -34.03082546   5.53852689 -27.88111874\n",
      " -26.94481529  11.81406045  14.26735556 -18.89733215 -28.88745333\n",
      "  15.60314713 -20.01474632 -33.75765008   6.17968028   7.39249018\n",
      "   3.44332817  11.57458148   3.33508829   5.57879699 -29.95797049\n",
      "  14.67651278 -25.80100256  14.81464628 -35.62132688 -29.56349012\n",
      "   1.82092194  -5.09654091   5.9549354  -35.27935397   6.66858295\n",
      " -22.26767873 -18.58199199  15.28202231  -0.66906745   3.22412895\n",
      "  24.84355581  26.52850606 -18.86830097 -19.53131789 -47.20927489\n",
      "  -7.37307234 -35.4348766   18.16365012  23.73602838 -33.34667432\n",
      "  16.62588244   4.81630652   3.85196303 -13.75762856  -2.60573921\n",
      "   5.75260225 -50.53656702 -39.46320916 -37.29090819 -13.53037856\n",
      "  14.7222935  -31.89314954   8.03112023 -24.41321275   2.64815005\n",
      " -32.6401345  -20.59008746 -29.56406959 -14.26471756  13.1537201\n",
      "   2.67331698 -22.54394989  -1.80604697   7.5775435  -27.26962469\n",
      " -34.48529588  -5.77012658 -31.25774675   6.177857    10.66680908\n",
      "  10.43096893  10.02618971 -40.47720205 -26.07972341 -43.93550075\n",
      " -38.28948731 -36.05170985 -30.75922143  -1.88692381  23.42020449\n",
      " -35.2145969  -41.25854238 -31.90904965 -20.16922453 -22.06134602\n",
      "  11.0854991   -8.20672556  25.07835181 -31.37839171 -30.01951875\n",
      "  -0.23705156 -26.72806372  -7.4111106    6.36040272  18.24695524\n",
      " -12.2330879  -27.69654449   9.61832099 -37.78826636  11.38529024\n",
      "  15.68168548 -20.69037201  -6.17021766 -39.44395165  15.19072451\n",
      " -41.20967802 -30.8426345    6.47411462   7.47799145 -30.7399141\n",
      "  17.28892378   6.7633367   24.4058979    5.00617404  16.05737174\n",
      " -12.64356458 -12.29964571 -34.13027461  12.65492787   9.73935302\n",
      " -27.07353979 -29.13565571 -33.96351869 -27.44379758  -2.96284864\n",
      "   1.96602462  13.05900708 -41.00048113   2.32013105  -9.85447309\n",
      " -12.06327377   4.77340744  15.23003365 -29.01356295   7.9755402\n",
      " -27.15424927 -43.59998926 -30.17062926  -9.79140257  13.41531205\n",
      "   0.91195342   1.89618793  29.66196281 -30.05090999  -3.96173577\n",
      "  20.04534757  22.08256889   0.82629443   3.03821489  -0.71035765\n",
      "  -0.41101088  12.93283858   1.83066847   3.63304903  27.73198777\n",
      " -38.6149368   20.52355453  -9.58079703  -5.11941095 -28.68403581\n",
      "   7.52453639  21.82397406 -29.55359657  10.61361976   4.14125637\n",
      "  -1.18708414   0.25263078  16.96969872 -10.33174989 -30.66496406\n",
      " -35.64950813  -7.37543398  19.3981204  -10.15907654  -4.99755097\n",
      "  30.03759291  30.44842611  15.70094473   5.74490836 -24.68411657\n",
      "  19.2544304  -29.2247218   15.56305319  -3.81370411 -30.23426828\n",
      "   0.25259334  10.70308856 -40.37742521  22.12020984 -22.92907648\n",
      " -21.9342724   -8.38673004 -17.07579358   9.75232412  -7.80936706\n",
      " -43.56397848  24.69113984  16.97926429  17.05246013 -34.88770271\n",
      " -44.65001784 -26.78056379 -21.87576934 -48.92045694  -2.48762599\n",
      " -27.04479348   7.16665987  -1.04415314]\n",
      "[-0.03747226  0.02530641 -0.021152   ... -0.01079098  0.00368432\n",
      "  0.00728066]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "mycebmf.init_LF()\n",
    "print(mycebmf.L[:,1])\n",
    "print(mycebmf.F[:,1])\n",
    "print(mycebmf.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\cEBMF.py:327: RuntimeWarning: divide by zero encountered in power\n",
      "  s_f = (denominator_f_hat) ** (-0.5)+1e-6\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\ash.py:47: RuntimeWarning: overflow encountered in exp\n",
      "  optimal_pi = optimize_pi( np.exp(L),\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\numerical_routine.py:237: RuntimeWarning: invalid value encountered in divide\n",
      "  w = w / w.sum(axis=0, keepdims=True)  # Normalize by sum over k for each j\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\numerical_routine.py:42: RuntimeWarning: overflow encountered in exp\n",
      "  scaled_res = -np.exp(dnorm_diff - pnorm_diff)\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\numerical_routine.py:86: RuntimeWarning: overflow encountered in exp\n",
      "  beta_frac = beta * np.exp(stats.norm.logpdf(beta) - pnorm_diff)\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\ash.py:58: RuntimeWarning: overflow encountered in exp\n",
      "  log_lik =    np.sum(np.log(np.sum(np.exp(L)*optimal_pi, axis=1)))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m60\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     mycebmf\u001b[38;5;241m.\u001b[39miter()\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\cEBMF.py:162\u001b[0m, in \u001b[0;36mcEBMF_object.iter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter\u001b[39m (\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK):\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_loading_factor_k(k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_tau()\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcal_obj()\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\cEBMF.py:152\u001b[0m, in \u001b[0;36mcEBMF_object.update_loading_factor_k\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mF  [:,k] \u001b[38;5;241m=\u001b[39mash_obj\u001b[38;5;241m.\u001b[39mpost_mean\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mF2 [:,k] \u001b[38;5;241m=\u001b[39mash_obj\u001b[38;5;241m.\u001b[39mpost_mean2\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_f[k]\u001b[38;5;241m=\u001b[39m ash_obj\u001b[38;5;241m.\u001b[39mlog_lik\u001b[38;5;241m-\u001b[39m  normal_means_loglik(x\u001b[38;5;241m=\u001b[39mfhat , \n\u001b[0;32m    153\u001b[0m                                    s\u001b[38;5;241m=\u001b[39m s_f,\n\u001b[0;32m    154\u001b[0m                                    Et\u001b[38;5;241m=\u001b[39mash_obj\u001b[38;5;241m.\u001b[39mpost_mean,\n\u001b[0;32m    155\u001b[0m                                    Et2\u001b[38;5;241m=\u001b[39m ash_obj\u001b[38;5;241m.\u001b[39mpost_mean2\n\u001b[0;32m    156\u001b[0m                                    )\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    mycebmf.iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f827ee6210>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.array(mycebmf.obj)[1:], marker='o', linestyle='-', color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Y' is the numpy array with your imputed data\n",
    "# Also assuming 'original_values' is the original DataFrame before you removed 20% of the data\n",
    "Y= mycebmf.Y_fit\n",
    "# Extract the original values that were removed (same as before)\n",
    "true_values = original_values.values[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "\n",
    "# Extract the corresponding imputed values from Y\n",
    "imputed_values = Y[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "\n",
    "# Check if their shapes match\n",
    "print(f\"True values shape: {true_values.shape}\")\n",
    "print(f\"Imputed values shape: {imputed_values.shape}\")\n",
    "\n",
    "# Calculate RMSE if shapes match\n",
    "if true_values.shape == imputed_values.shape:\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, imputed_values))\n",
    "    print(f'RMSE for your custom imputation method: {rmse}')\n",
    "else:\n",
    "    print(\"Error: Shape mismatch between true values and imputed values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "mycebmf.cal_partial_residuals(k=k)\n",
    "lhat , s_l  = compute_hat_l_and_s_l(Z = mycebmf.Rk,\n",
    "                                                            nu = mycebmf.F[:,k] ,\n",
    "                                                            omega= mycebmf.F2[:,k], \n",
    "                                                            tau= mycebmf.tau,\n",
    "                                                            has_nan=mycebmf.has_nan)\n",
    " \n",
    "betahat   =lhat\n",
    "sebetahat =s_l \n",
    "prior     = mycebmf.prior_L\n",
    "verbose=False\n",
    "mult=np.sqrt(2) \n",
    "\n",
    "\n",
    "\n",
    "np.isinf (lhat ).any()\n",
    "sebetahat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ash_obj = ash(betahat   =lhat,\n",
    "                      sebetahat =s_l ,\n",
    "                      prior     = mycebmf.prior_L,\n",
    "                      verbose=False\n",
    "                      )\n",
    "print(ash_obj.post_mean)\n",
    "mycebmf.L  [:,k] =ash_obj.post_mean\n",
    "mycebmf.L2 [:,k] =ash_obj.post_mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "mycebmf.cal_partial_residuals(k=k)\n",
    "\n",
    "fhat , s_f  = compute_hat_f_and_s_f(Z = mycebmf.Rk,\n",
    "                                                            nu = mycebmf.L[:,k] ,\n",
    "                                                            omega= mycebmf.L2[:,k], \n",
    "                                                            tau= mycebmf.tau,\n",
    "                                                            has_nan=mycebmf.has_nan)\n",
    "plt.scatter(s_f, fhat)\n",
    "\n",
    "ash_obj = ash(betahat   =fhat,\n",
    "                      sebetahat =s_f ,\n",
    "                      prior     = mycebmf.prior_F,\n",
    "                      verbose=False\n",
    "                      )\n",
    "print(ash_obj.scale)\n",
    "\n",
    "mycebmf.F  [:,k] =ash_obj.post_mean\n",
    "mycebmf.F2 [:,k] =ash_obj.post_mean2\n",
    "print(ash_obj.log_lik2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat   =fhat \n",
    "sebetahat =s_f  +1e-7\n",
    "prior     = mycebmf.prior_F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=autoselect_scales_mix_exp(betahat  = betahat,\n",
    "                                         sebetahat= sebetahat,\n",
    "                                          mult=np.sqrt(2))\n",
    "\n",
    "L= get_data_loglik_exp(betahat=betahat ,\n",
    "                                 sebetahat=sebetahat , \n",
    "                                 scale=scale)\n",
    "optimal_pi = optimize_pi( np.exp(L),\n",
    "                                 penalty=10,\n",
    "                                 verbose=True)  \n",
    "log_pi=  np.tile(np.log(optimal_pi+1e-32), (betahat.shape[0],1))\n",
    "        \n",
    "out= posterior_mean_exp(betahat, sebetahat,\n",
    "                                 log_pi=log_pi, \n",
    "                                 scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_pi\n",
    "plt.scatter(optimal_pi, range(optimal_pi.shape[0]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fhat,out.post_mean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=autoselect_scales_mix_exp(betahat  = betahat,\n",
    "                                         sebetahat= sebetahat,\n",
    "                                          mult=np.sqrt(2))\n",
    "L= get_data_loglik_exp(betahat=betahat ,\n",
    "                                 sebetahat=sebetahat , \n",
    "                                 scale=scale)\n",
    "optimal_pi = optimize_pi( np.exp(L),\n",
    "                                 penalty=penalty,\n",
    "                                 verbose=verbose)  \n",
    "log_pi=  np.tile(np.log(optimal_pi+1e-32), (betahat.shape[0],1))\n",
    "        \n",
    "out= posterior_mean_exp(betahat, sebetahat,\n",
    "                                 log_pi=log_pi, \n",
    "                                 scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmaamax  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_f=1e-8+s_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat   =lhat\n",
    "sebetahat =s_l \n",
    "prior     = mycebmf.prior_L\n",
    "verbose=False\n",
    "mult=np.sqrt(2)\n",
    "\n",
    "plt.scatter(betahat, sebetahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(1e-32)\n",
    " \n",
    "plt.scatter(betahat,np.log(sebetahat))\n",
    "plt.axvline(x=0, color='red', linestyle='--')  # Add a horizontal line at y=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ash_obj.post_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(s_f, fhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=autoselect_scales_mix_exp(betahat  = betahat,\n",
    "                                         sebetahat= sebetahat,\n",
    "                                          mult=1.5)\n",
    "print(scale)\n",
    "L= get_data_loglik_exp(betahat=betahat ,\n",
    "                                 sebetahat=sebetahat , \n",
    "                                 scale=scale)\n",
    "optimal_pi = optimize_pi( np.exp(L),\n",
    "                                 penalty=10,\n",
    "                                 verbose=verbose)  \n",
    "print((L[5,:]))\n",
    "sebetahat[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycebmf.Rk[5,:]\n",
    "np.isnan(mycebmf.Rk[5,:]).sum()\n",
    "mycebmf.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pi=  np.tile(np.log(optimal_pi+1e-32), (betahat.shape[0],1))\n",
    "        \n",
    "out= posterior_mean_exp(betahat, sebetahat,\n",
    "                                 log_pi=log_pi, \n",
    "                                 scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sebetahat = sebetahat[betahat == 0]\n",
    "subset_sebetahat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = mycebmf.Rk\n",
    "nu = mycebmf.F[:,k] \n",
    "omega= mycebmf.F2[:,k]\n",
    "tau= mycebmf.tau\n",
    "has_nan=mycebmf.has_nan\n",
    " \n",
    "numerator_l_hat = np.sum(tau * Z * nu, axis=1)\n",
    "denominator_l_hat = np.sum(tau * omega, axis=1) + 1e-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator_l_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
