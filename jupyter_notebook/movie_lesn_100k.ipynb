{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "\n",
    "# Step 1: Load MovieLens 100k data from file or URL\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.data'\n",
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(url, sep='\\t', names=column_names)\n",
    "\n",
    "# Create a pivot table (user-item matrix) for ratings\n",
    "ratings_matrix = df.pivot(index='user_id', columns='item_id', values='rating')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import svds\n",
    " \n",
    "# Step 3: Identify non-NA entries in the ratings matrix\n",
    "non_na_mask = ratings_matrix.notna()\n",
    "\n",
    "# Convert mask to a list of non-NA (user, item) pairs\n",
    "non_na_indices = np.argwhere(non_na_mask.values)  # Get (row, col) indices of non-NA values\n",
    "\n",
    "# Randomly select 20% of non-NA entries to introduce missing data\n",
    "n_remove = int(0.2 * len(non_na_indices))  # 20% of available data\n",
    "remove_indices = np.random.choice(np.arange(len(non_na_indices)), size=n_remove, replace=False)\n",
    "\n",
    "# Save the original values that will be removed for later evaluation\n",
    "original_values = ratings_matrix.copy()\n",
    "\n",
    "# Step 4: Introduce missing values\n",
    "ratings_matrix_masked = ratings_matrix.copy()\n",
    "\n",
    "# Set the selected 20% of data points to NaN\n",
    "for index in remove_indices:\n",
    "    row, col = non_na_indices[index]  # Get the (row, col) pair\n",
    "    ratings_matrix_masked.iloc[row, col] = np.nan  # Set the value at that position to NaN\n",
    "\n",
    "# Step 5: Fill the missing values with 0 for SVD input (other methods can be used here)\n",
    "R_filled = ratings_matrix_masked.fillna(0).values\n",
    "\n",
    "# Step 6: Apply SVD (Singular Value Decomposition)\n",
    "# Decompose the matrix using SVD\n",
    "U, sigma, Vt = svds(R_filled, k=50)  # Using 50 latent factors\n",
    "sigma = np.diag(sigma)  # Convert sigma (1D array) to a diagonal matrix\n",
    "\n",
    "# Reconstruct the matrix using the decomposed matrices\n",
    "R_predicted = np.dot(np.dot(U, sigma), Vt)\n",
    "\n",
    "# Step 7: Evaluate performance of the SVD model\n",
    "# Create a DataFrame for the predicted ratings\n",
    "imputed_ratings = pd.DataFrame(R_predicted, columns=ratings_matrix.columns, index=ratings_matrix.index)\n",
    "\n",
    "# Calculate RMSE on the originally removed 20% of the data\n",
    "true_values = original_values.iloc[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "predicted_values = imputed_ratings.iloc[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values shape: (20000,)\n",
      "Predicted values shape: (20000,)\n",
      "RMSE for the SVD-based prediction: 2.8850733488134606\n"
     ]
    }
   ],
   "source": [
    "# Extract the values from the original matrix and imputed matrix for comparison\n",
    "true_values = original_values.values[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "predicted_values = imputed_ratings.values[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "\n",
    "# Check if their shapes match\n",
    "print(f\"True values shape: {true_values.shape}\")\n",
    "print(f\"Predicted values shape: {predicted_values.shape}\")\n",
    "\n",
    "# Calculate RMSE if shapes match\n",
    "if true_values.shape == predicted_values.shape:\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "    print(f'RMSE for the SVD-based prediction: {rmse}')\n",
    "else:\n",
    "    print(\"Error: Shape mismatch between true values and predicted values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                              ...   \n",
       "1         5.0   NaN   NaN   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5         NaN   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "940       NaN   NaN   NaN   2.0   NaN   NaN   4.0   5.0   3.0   NaN  ...   \n",
       "941       5.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   \n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "943       NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN  ...   \n",
       "\n",
       "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user_id                                                              \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "940       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "941       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "943       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix_masked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fancyimpute import IterativeSVD\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the path to utils.py\n",
    "sys.path.append(r\"c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\")\n",
    "from cEBMF import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycebmf= cEBMF(data= np.array(ratings_matrix_masked), K=12,\n",
    "               prior_L = \"exp\",\n",
    "               prior_F = \"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The array contains missing values (NaN), generate initialization using iterive svd.\n",
      "[IterativeSVD] Iter 1: observed MAE=2.681945\n",
      "[IterativeSVD] Iter 2: observed MAE=2.143082\n",
      "[IterativeSVD] Iter 3: observed MAE=1.731446\n",
      "[IterativeSVD] Iter 4: observed MAE=1.414475\n",
      "[IterativeSVD] Iter 5: observed MAE=1.217622\n",
      "[IterativeSVD] Iter 6: observed MAE=1.097855\n",
      "[IterativeSVD] Iter 7: observed MAE=1.016646\n",
      "[IterativeSVD] Iter 8: observed MAE=0.957873\n",
      "[IterativeSVD] Iter 9: observed MAE=0.913194\n",
      "[IterativeSVD] Iter 10: observed MAE=0.878158\n",
      "[IterativeSVD] Iter 11: observed MAE=0.849851\n",
      "[IterativeSVD] Iter 12: observed MAE=0.826423\n",
      "[IterativeSVD] Iter 13: observed MAE=0.806774\n",
      "[IterativeSVD] Iter 14: observed MAE=0.790036\n",
      "[IterativeSVD] Iter 15: observed MAE=0.775611\n",
      "[IterativeSVD] Iter 16: observed MAE=0.763005\n",
      "[IterativeSVD] Iter 17: observed MAE=0.751925\n",
      "[IterativeSVD] Iter 18: observed MAE=0.742072\n",
      "[IterativeSVD] Iter 19: observed MAE=0.733229\n",
      "[IterativeSVD] Iter 20: observed MAE=0.725243\n",
      "[IterativeSVD] Iter 21: observed MAE=0.717990\n",
      "[IterativeSVD] Iter 22: observed MAE=0.711371\n",
      "[IterativeSVD] Iter 23: observed MAE=0.705305\n",
      "[IterativeSVD] Iter 24: observed MAE=0.699721\n",
      "[IterativeSVD] Iter 25: observed MAE=0.694561\n",
      "[IterativeSVD] Iter 26: observed MAE=0.689780\n",
      "[IterativeSVD] Iter 27: observed MAE=0.685329\n",
      "[IterativeSVD] Iter 28: observed MAE=0.681180\n",
      "[IterativeSVD] Iter 29: observed MAE=0.677298\n",
      "[IterativeSVD] Iter 30: observed MAE=0.673651\n",
      "[IterativeSVD] Iter 31: observed MAE=0.670215\n",
      "[IterativeSVD] Iter 32: observed MAE=0.666974\n",
      "[IterativeSVD] Iter 33: observed MAE=0.663916\n",
      "[IterativeSVD] Iter 34: observed MAE=0.661025\n",
      "[IterativeSVD] Iter 35: observed MAE=0.658282\n",
      "[IterativeSVD] Iter 36: observed MAE=0.655680\n",
      "[IterativeSVD] Iter 37: observed MAE=0.653206\n",
      "[IterativeSVD] Iter 38: observed MAE=0.650846\n",
      "[IterativeSVD] Iter 39: observed MAE=0.648589\n",
      "[IterativeSVD] Iter 40: observed MAE=0.646432\n",
      "[IterativeSVD] Iter 41: observed MAE=0.644367\n",
      "[IterativeSVD] Iter 42: observed MAE=0.642386\n",
      "[IterativeSVD] Iter 43: observed MAE=0.640487\n",
      "[IterativeSVD] Iter 44: observed MAE=0.638661\n",
      "[IterativeSVD] Iter 45: observed MAE=0.636905\n",
      "[IterativeSVD] Iter 46: observed MAE=0.635219\n",
      "[IterativeSVD] Iter 47: observed MAE=0.633594\n",
      "[IterativeSVD] Iter 48: observed MAE=0.632026\n",
      "[IterativeSVD] Iter 49: observed MAE=0.630513\n",
      "[IterativeSVD] Iter 50: observed MAE=0.629052\n",
      "[IterativeSVD] Iter 51: observed MAE=0.627638\n",
      "[IterativeSVD] Iter 52: observed MAE=0.626270\n",
      "[IterativeSVD] Iter 53: observed MAE=0.624946\n",
      "[IterativeSVD] Iter 54: observed MAE=0.623661\n",
      "[IterativeSVD] Iter 55: observed MAE=0.622415\n",
      "[IterativeSVD] Iter 56: observed MAE=0.621206\n",
      "[IterativeSVD] Iter 57: observed MAE=0.620032\n",
      "[IterativeSVD] Iter 58: observed MAE=0.618892\n",
      "[IterativeSVD] Iter 59: observed MAE=0.617786\n",
      "[IterativeSVD] Iter 60: observed MAE=0.616712\n",
      "[IterativeSVD] Iter 61: observed MAE=0.615667\n",
      "[IterativeSVD] Iter 62: observed MAE=0.614649\n",
      "[IterativeSVD] Iter 63: observed MAE=0.613659\n",
      "[IterativeSVD] Iter 64: observed MAE=0.612693\n",
      "[IterativeSVD] Iter 65: observed MAE=0.611752\n",
      "[IterativeSVD] Iter 66: observed MAE=0.610836\n",
      "[IterativeSVD] Iter 67: observed MAE=0.609941\n",
      "[IterativeSVD] Iter 68: observed MAE=0.609068\n",
      "[IterativeSVD] Iter 69: observed MAE=0.608216\n",
      "[IterativeSVD] Iter 70: observed MAE=0.607384\n",
      "[IterativeSVD] Iter 71: observed MAE=0.606571\n",
      "[IterativeSVD] Iter 72: observed MAE=0.605778\n",
      "[IterativeSVD] Iter 73: observed MAE=0.605003\n",
      "[IterativeSVD] Iter 74: observed MAE=0.604246\n",
      "[IterativeSVD] Iter 75: observed MAE=0.603507\n",
      "[IterativeSVD] Iter 76: observed MAE=0.602782\n",
      "[IterativeSVD] Iter 77: observed MAE=0.602074\n",
      "[IterativeSVD] Iter 78: observed MAE=0.601379\n",
      "[IterativeSVD] Iter 79: observed MAE=0.600699\n",
      "[IterativeSVD] Iter 80: observed MAE=0.600032\n",
      "[IterativeSVD] Iter 81: observed MAE=0.599378\n",
      "[IterativeSVD] Iter 82: observed MAE=0.598738\n",
      "[IterativeSVD] Iter 83: observed MAE=0.598110\n",
      "[  2.50212813 -40.13652813 -16.23696185 -38.79167283  18.99951805\n",
      "  14.69349387  22.35945102  -2.87423928   2.36914195  16.59977393\n",
      "   6.08635634   0.43131308   9.23072765  18.88554327 -34.25211423\n",
      "  26.80746988 -18.68856644  16.09555671  -3.13928827  -5.92318592\n",
      "  -2.97185593  13.58871386  18.81539434   4.33918183  14.54620717\n",
      " -29.29457965 -23.07072493   5.52761155  -8.61212704 -10.54947378\n",
      "  14.51313216 -30.57169407 -35.8998996  -31.84733498 -28.79950735\n",
      " -36.62413891  -5.03333006  -0.34302663 -30.17078834 -32.81323186\n",
      "  17.33360484  12.67619254   2.16260848  13.75102911 -26.65500361\n",
      " -38.55405012 -30.49254737  13.99781638   9.32666223 -20.74497825\n",
      "  -1.88378461  -8.01672348 -11.76558112 -38.61769572  -5.50324249\n",
      "   2.64350104 -23.77347082  -7.16019702   9.74631058  21.57854793\n",
      " -24.78337498  11.07024127 -26.40027882  15.6628715   13.64845359\n",
      " -29.02081097 -18.22589953 -24.70208094 -12.9065192   11.32833833\n",
      "  12.14738112  21.09853745  12.06938254 -35.08544931  -7.67160203\n",
      "  -4.02283416  22.06906062 -35.40961322 -35.77626846   4.23877486\n",
      " -13.75677228  12.9160495    7.92136293  -2.89679023  13.42675381\n",
      " -36.53526893   9.34109922 -32.90063632 -17.65140378  13.97651227\n",
      "  -3.25685893  10.01493118 -18.29688317  20.6234145    9.04963975\n",
      "  21.41847222  20.46325189   9.76736652 -21.82587824 -32.97488401\n",
      " -29.35428772   6.39026058 -13.05773326 -31.61571023 -31.3281189\n",
      "   5.68554911 -21.77435297 -19.4171434   -2.65544194   1.21262577\n",
      " -28.19780334 -41.73882252 -59.15676468  15.65888801   9.79485489\n",
      "  -3.48985799 -16.16636642  17.28541554  -5.88744505 -24.73149687\n",
      "   6.3448039   38.31588234  19.29084669   3.58505699  11.12174174\n",
      " -32.84563287 -18.81049131  20.02053368 -21.16271364  -5.53500872\n",
      " -34.92700689  10.4470336  -28.37090351 -32.93749126  -1.03453057\n",
      "   4.47406214 -29.32734906  21.3702312  -41.45261171 -25.76591858\n",
      " -35.22474298  -6.23181612 -35.13480095   1.22900113  -4.55590576\n",
      " -39.14175181 -32.61244609  16.50704033 -26.80499964 -26.92886679\n",
      "  19.14195765   7.83365467  -8.16317755  14.76776788 -24.87751728\n",
      "  20.77457921 -40.1100973   20.9410779  -29.36372263  11.52669303\n",
      " -14.04505118 -13.45537439  -9.95906964 -46.98981061  -2.1598847\n",
      " -31.59788463  24.39903444 -30.16539002  -5.80197441 -35.95006512\n",
      " -29.82060405  29.50570463 -44.1489481   -2.75900399   9.44120017\n",
      " -36.65528731   3.28181753  -0.77838872 -31.03256598   8.61670733\n",
      " -20.17515328  -4.57227009   8.12341764  11.88138816   9.45248386\n",
      " -12.98305681  10.25936837  12.45392806  11.32221589 -39.21719396\n",
      " -21.63992322 -40.11948622   7.55247341  19.59305205  -9.56477855\n",
      "   8.53462158  -8.41909501   6.62962874 -23.49099827  10.89469179\n",
      "   4.6592858    2.93328065 -36.14044698  -5.8608839  -26.90659029\n",
      " -29.26356716   3.45354138  18.87724436 -30.95280122  10.1925541\n",
      "  -8.35461955  15.67728887  14.39657914   8.13205029  15.05962878\n",
      "   3.29708478   1.12701743  12.91021022   1.34472975 -34.79328626\n",
      "   2.92452041  -1.98785206 -15.65824543  -2.27101639  21.21437053\n",
      "  -9.84385641 -27.58314008 -10.74467758 -23.85888015   7.13834092\n",
      " -23.83950453  12.69640924  10.6990803   12.12464522   9.72443804\n",
      "   3.30001057  18.23111628 -32.60639569  33.33798054 -32.91405135\n",
      " -32.04936344 -50.68780791  15.63028908  11.92704253 -22.11202651\n",
      "   3.52729425  -4.35372327  -7.31812178   9.2394285    0.97336483\n",
      "   7.26851298 -28.30383382   6.29688335   6.75587466 -17.84492884\n",
      " -15.39305059 -12.39215721 -36.89720102   0.4353334  -40.35560892\n",
      " -45.88610797   4.29620614  20.61591512  20.2484209  -36.68033373\n",
      " -19.10432998  17.551491     4.90155693  22.70972881 -10.78105699\n",
      "  13.36116762  11.42655165 -26.51245404  -0.57840165  13.51776047\n",
      "   9.09251486 -33.5801132   -8.5787134    6.0053016    2.82663075\n",
      " -31.5069799  -28.68659521   8.66252696 -32.01534735 -13.14872962\n",
      " -15.19027819  -8.46705083  -4.0569221  -22.46354548   1.57015737\n",
      "  14.26241678  18.0998903   17.64217388 -31.83455324  29.37107338\n",
      "  -8.9407473   -3.84165933  13.6541526    6.97656086 -45.70232026\n",
      "   5.4186197  -22.9899929   13.02286942 -37.15614503   6.84420255\n",
      " -28.57353474  16.38807155  15.64355442 -35.43601441 -30.27645908\n",
      "   5.87671401  26.33607219  16.06085388 -13.89703202   8.34599434\n",
      "   8.37636705 -36.61639813  12.70969797 -34.84846481  -4.10646134\n",
      "  19.98609991   9.39590032  -5.44211582 -57.19443624  33.42327904\n",
      "  30.21001434   8.26484598   3.2570677   -8.69270734   9.7822668\n",
      "  10.50554836  -8.60551937  -6.62267367   1.54481291 -34.64033854\n",
      "   1.19334016   5.4784068   21.70218281  19.73046886  15.29572189\n",
      " -39.55828856  18.36656805  15.81991454   8.17947813   2.23159207\n",
      "   4.70783814   5.12412664 -39.83048499 -22.9563802   10.13203352\n",
      " -39.66121924   2.69120197 -28.70999047   2.57995662 -41.65961284\n",
      " -33.27445492 -38.81384772   8.05235028 -30.67288083   5.21462697\n",
      "  22.41183115 -37.76616851   7.40695144 -35.47424086 -39.41668605\n",
      "  16.06683201  -9.65693277 -13.74881961 -19.14693765  17.28630939\n",
      "   3.19173915  -9.72391271  15.62279907   0.15508915   2.16693395\n",
      "  -1.17653086  -5.51756911  11.85522679  17.19119623   9.17938299\n",
      "  11.50296597  17.07613502  28.46005061 -40.72629901  11.98040053\n",
      " -24.13049929  15.4517873  -24.51927702  19.54317953 -34.6212355\n",
      "  14.34291654   3.33456621   0.83410345   6.04374235   2.94957555\n",
      " -36.93347174  12.33536559  21.53879733   1.39945398 -30.02881916\n",
      "   7.02605646  -1.9781371  -24.9956151  -21.54775679  -6.60319061\n",
      "  22.49957642  12.12466363 -35.61825196   9.9377285  -27.41879801\n",
      "  10.17065049   2.30973665 -35.84321704 -24.792334     0.24426979\n",
      "   1.47879846   9.44026166 -28.64665928   7.48081279   0.5247548\n",
      "  -0.57847532  -5.35125504 -41.17178448 -22.53752643  -2.0777821\n",
      "  18.41613088 -48.68850042 -44.20020377   7.57693388   3.44658838\n",
      " -31.99980142 -38.18417957  -3.36900112 -29.00220901   2.19292081\n",
      "   0.86059834  30.01206108 -33.64230223 -31.99311919 -23.75614005\n",
      " -30.86810919   4.16376696 -21.48449348 -34.98139903   1.65019645\n",
      " -25.75629805  -2.06573646 -26.86196217  -4.7920156    7.25354606\n",
      " -43.70148624   9.22834659  -0.75712487  -8.30021068  -0.20672644\n",
      "  10.42806655  20.11356055   3.72119923 -28.6619403  -34.05757754\n",
      " -17.45027823 -19.89218292 -33.94667688 -19.35333881  10.96717069\n",
      " -28.95506279 -28.63118427  15.6147653   24.48862804 -38.60876148\n",
      "  -0.13830677  -4.00565018 -24.86371571  11.68887934 -18.66303692\n",
      "   6.06206551 -13.67969113  -2.87087877   9.12753402   8.18244901\n",
      "  11.82825144 -39.56457614   0.72144442   7.57092665 -24.75777622\n",
      " -37.37401242  10.34377835   5.52327056 -43.73121812 -19.66541012\n",
      "  -3.83520794   2.5963303   -0.84098075  -2.38495677  23.40603942\n",
      "  14.52446682   2.02004925  12.39263677  -1.06313254  10.11893779\n",
      " -38.5397483  -31.79269637   5.44430675   8.9419097    6.64315239\n",
      "  13.38722351 -56.99975639  27.93371854  -8.97509324 -30.0213311\n",
      " -43.32355448   0.40397356 -16.3959501    3.40113418 -33.88708336\n",
      "  -1.74037536 -17.46377004 -31.13746518 -36.96030366 -30.67565456\n",
      "  -5.91521382  27.4897924   -0.84115293  -5.95979814 -33.86635346\n",
      " -27.50811577  20.56173703   1.6063549  -35.41006704  -0.63308483\n",
      " -35.20408484   0.70024891  -2.66004394 -43.6152531   21.13582395\n",
      "  24.80872143  10.37317369  11.35796259  17.25913061 -38.22148318\n",
      "  19.84327282  19.95510594  11.12303274 -26.5934733   10.72228846\n",
      " -16.77085362 -31.13828069 -14.11753087 -27.22198062 -40.3321074\n",
      "  -8.21803774 -36.95021914  23.73428608   1.56593751  -5.14564436\n",
      "  13.32752999 -13.19097385 -23.06701768   7.1315165   -2.66706869\n",
      "  11.08819434  25.2377979    1.66485794 -38.30989086  21.07837363\n",
      "  25.79638665  23.83096838   9.96362128 -30.19345788 -22.18980174\n",
      "  11.03516019 -23.8943158   13.19934758 -30.66704261   3.80394291\n",
      " -12.23737999  17.51688547 -21.17886133   2.27938713 -42.35702569\n",
      " -17.82226003 -30.12371406  20.73254157  -9.82043832   5.93699065\n",
      "  -5.12303393 -35.63721901   4.27644833 -36.64162522 -22.52098829\n",
      "  14.87648234   2.56317362   9.41975135  -7.81436668 -36.54364164\n",
      " -34.27293675 -39.08129311 -33.33371488 -44.77760792  14.32180268\n",
      "  13.45991509 -39.56147657 -11.63577612   4.89126057   3.83159906\n",
      "   4.54857311  11.17487223  11.44220688 -30.17223302  14.01937731\n",
      " -35.09185505  -4.9275614   -3.71026375 -24.52008595  15.89450607\n",
      " -38.63853591  20.06473852   7.33084472 -11.17944521   5.45240192\n",
      "  -0.99704036  16.1627429   16.2883905  -42.40042821  14.17120639\n",
      " -16.86501784  15.38978095 -44.53444552  -2.3162721  -25.68665242\n",
      " -29.66321665  20.16765068   4.56620559 -37.46529847 -34.41558781\n",
      " -31.3498683  -33.1261393    1.27271469  19.38599574  -1.53456514\n",
      "  14.73631767  -4.29034163  22.11414891 -49.04125803  25.38486924\n",
      " -33.4879502   11.93450407  16.21324048 -29.48325466  16.2914425\n",
      " -20.7073188  -18.9655908   -7.9421271    0.76550009   0.92159279\n",
      " -19.36861542 -24.54094284  12.05597583  12.91062513   6.20853794\n",
      "  14.75694675 -23.90714159 -17.11577143  21.57471622  -8.89260447\n",
      "   9.6104841    5.53655555 -24.03785459   6.97988481  21.05707359\n",
      "  -2.41587904 -32.70828985 -23.92046072 -36.09573244   5.44556298\n",
      " -12.1625986  -32.30332483 -27.83461956   3.88531882 -11.18835626\n",
      " -25.10028809   0.36390631   2.80592041   9.6267237  -18.45892775\n",
      "  14.96030802 -32.07506287 -44.50115163 -35.90538087   9.99275073\n",
      "  23.15153125 -12.25827872  12.18460836  25.43966228 -29.28822228\n",
      "  -3.33927464 -46.95101201   6.20013372 -24.79187314   3.1851268\n",
      " -33.38399031  -8.49615325 -26.83166448  17.9308146   -6.65720542\n",
      " -28.19606957   2.0850648  -40.74795772  -0.90425168   9.44071618\n",
      "   9.43484046  -2.42663391 -22.368852   -33.06525646   0.25897233\n",
      "  16.09708114 -50.53222873 -38.31107993   9.76399906 -32.95630271\n",
      " -10.23573356 -30.18914416  -5.43852598 -26.81856257 -32.99142045\n",
      " -37.17806354   3.53472027 -32.57516269 -25.5763087  -27.76220275\n",
      "  20.43591566 -31.87212533 -30.16303985   9.41125489 -24.82915448\n",
      " -28.75863339   6.96716626  13.57511778 -24.84503604 -30.24120915\n",
      "  19.13017939 -19.92373016 -31.31376337   0.59938849   7.7251088\n",
      "   6.35554909  11.21852809   5.12166946  10.11093266 -33.11018758\n",
      "  15.6322933  -27.75472491   5.48193937 -35.31124589 -32.70875583\n",
      "   6.21562132   0.68306847   6.23875058 -33.62700346   0.75505084\n",
      " -19.32891586 -20.70476322  26.77489623  -1.58351804   3.12740181\n",
      "  22.85734192  20.97013517 -16.61195968 -26.04800155 -46.33930409\n",
      "  -3.45671832 -39.65511116  18.19737146  15.52879322 -30.86893271\n",
      "  22.57395601  -4.59159167   2.78028609 -18.02129314   2.29348432\n",
      "   2.22943748 -50.33590231 -37.75096327 -39.40611661  -9.60995405\n",
      "  13.06292869 -36.7085101    3.44258891 -24.34439482   5.073462\n",
      " -29.55034586 -21.88820143 -32.06114811 -13.28698173  11.6475817\n",
      "   3.50896929 -22.52919236  -0.93213185   5.98555871 -23.86120245\n",
      " -40.33326269  -4.95276202 -29.17047681   5.93196382  10.28748139\n",
      "  12.55484954  16.60087465 -39.09927406 -26.16528622 -44.57704988\n",
      " -37.65417996 -34.87826862 -36.31206693  -2.58015525  29.80486838\n",
      " -35.26319293 -35.47197541 -33.05472497 -32.43347006 -22.66115397\n",
      "  13.43658521  -6.57369155  25.04428698 -26.22296883 -20.04368027\n",
      "  -1.73550657 -28.97894224  -7.25996045   4.34291635  18.66881848\n",
      " -11.75342863 -29.15349562   3.85761944 -36.20382149  14.65514936\n",
      "  13.66231896 -22.44656519  -1.6926359  -38.99360307  16.51026055\n",
      " -42.57738173 -31.31704974   8.19454939   5.28615447 -32.02763811\n",
      "  16.29110602   4.92846378  21.59675361   2.01089951  12.82807602\n",
      " -11.29995139  -5.1247155  -32.09939751  12.87078618  14.36870673\n",
      " -30.53506351 -32.4265405  -35.85188819 -21.1243398  -11.3783122\n",
      "   5.91941755  13.0463423  -39.75573453   0.68942755  -9.58937623\n",
      " -12.8222135   -6.34687543  14.30033407 -28.77122449   6.25110419\n",
      " -27.83709777 -40.82029003 -28.62953859  -6.18101218  13.60269923\n",
      "   3.56060476   5.33937353  27.23774574 -31.21392676  -3.54525517\n",
      "  19.75970385  21.72968685   4.32201484   3.57475811   3.42372463\n",
      "  -3.36250565   3.11588684  -3.06650649   0.26478798  26.7685611\n",
      " -35.04537211  21.79367619 -11.81774331  -2.11765267 -24.68755357\n",
      "   8.12984965  23.21530553 -29.23689895   2.86400223   4.43622282\n",
      "   8.55728132 -11.66650197  22.16472272  -9.74490273 -33.21984714\n",
      " -30.02235006  -9.76740643  18.12781573 -10.24372632  -2.09823906\n",
      "  23.85175119  29.54649508   4.69748534   6.7004969  -26.14500069\n",
      "  15.95335841 -28.23805737  20.39803893  -5.66184611 -30.41743326\n",
      "  -0.33665568  13.24495769 -38.30736419  13.60332221 -15.7906074\n",
      " -25.30187719  -8.82111512 -17.97152363   6.6296116  -10.20166358\n",
      " -40.93085373  26.64488998  19.03752568  15.07037883 -31.87412026\n",
      " -46.29937697 -24.40263109 -31.33433206 -44.8271344   -2.91699865\n",
      " -25.93819451   7.86462021   2.74053473]\n",
      "[-0.03786747  0.02577785 -0.02565284 ... -0.01086682  0.00472138\n",
      "  0.00673696]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "mycebmf.init_LF()\n",
    "print(mycebmf.L[:,1])\n",
    "print(mycebmf.F[:,1])\n",
    "print(mycebmf.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\cEBMF.py:327: RuntimeWarning: divide by zero encountered in power\n",
      "  s_f = (denominator_f_hat) ** (-0.5)+1e-6\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\ash.py:47: RuntimeWarning: overflow encountered in exp\n",
      "  optimal_pi = optimize_pi( np.exp(L),\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\numerical_routine.py:237: RuntimeWarning: invalid value encountered in divide\n",
      "  w = w / w.sum(axis=0, keepdims=True)  # Normalize by sum over k for each j\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\numerical_routine.py:42: RuntimeWarning: overflow encountered in exp\n",
      "  scaled_res = -np.exp(dnorm_diff - pnorm_diff)\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\numerical_routine.py:86: RuntimeWarning: overflow encountered in exp\n",
      "  beta_frac = beta * np.exp(stats.norm.logpdf(beta) - pnorm_diff)\n",
      "c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\ash.py:58: RuntimeWarning: overflow encountered in exp\n",
      "  log_lik =    np.sum(np.log(np.sum(np.exp(L)*optimal_pi, axis=1)))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m60\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     mycebmf\u001b[38;5;241m.\u001b[39miter()\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\cEBMF.py:162\u001b[0m, in \u001b[0;36mcEBMF_object.iter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter\u001b[39m (\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK):\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_loading_factor_k(k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_tau()\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcal_obj()\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\cEBMF.py:152\u001b[0m, in \u001b[0;36mcEBMF_object.update_loading_factor_k\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mF  [:,k] \u001b[38;5;241m=\u001b[39mash_obj\u001b[38;5;241m.\u001b[39mpost_mean\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mF2 [:,k] \u001b[38;5;241m=\u001b[39mash_obj\u001b[38;5;241m.\u001b[39mpost_mean2\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_f[k]\u001b[38;5;241m=\u001b[39m ash_obj\u001b[38;5;241m.\u001b[39mlog_lik\u001b[38;5;241m-\u001b[39m  normal_means_loglik(x\u001b[38;5;241m=\u001b[39mfhat , \n\u001b[0;32m    153\u001b[0m                                    s\u001b[38;5;241m=\u001b[39m s_f,\n\u001b[0;32m    154\u001b[0m                                    Et\u001b[38;5;241m=\u001b[39mash_obj\u001b[38;5;241m.\u001b[39mpost_mean,\n\u001b[0;32m    155\u001b[0m                                    Et2\u001b[38;5;241m=\u001b[39m ash_obj\u001b[38;5;241m.\u001b[39mpost_mean2\n\u001b[0;32m    156\u001b[0m                                    )\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    mycebmf.iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.array(mycebmf.obj)[1:], marker='o', linestyle='-', color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Y' is the numpy array with your imputed data\n",
    "# Also assuming 'original_values' is the original DataFrame before you removed 20% of the data\n",
    "Y= mycebmf.Y_fit\n",
    "# Extract the original values that were removed (same as before)\n",
    "true_values = original_values.values[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "\n",
    "# Extract the corresponding imputed values from Y\n",
    "imputed_values = Y[non_na_indices[remove_indices][:, 0], non_na_indices[remove_indices][:, 1]]\n",
    "\n",
    "# Check if their shapes match\n",
    "print(f\"True values shape: {true_values.shape}\")\n",
    "print(f\"Imputed values shape: {imputed_values.shape}\")\n",
    "\n",
    "# Calculate RMSE if shapes match\n",
    "if true_values.shape == imputed_values.shape:\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, imputed_values))\n",
    "    print(f'RMSE for your custom imputation method: {rmse}')\n",
    "else:\n",
    "    print(\"Error: Shape mismatch between true values and imputed values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "mycebmf.cal_partial_residuals(k=k)\n",
    "lhat , s_l  = compute_hat_l_and_s_l(Z = mycebmf.Rk,\n",
    "                                                            nu = mycebmf.F[:,k] ,\n",
    "                                                            omega= mycebmf.F2[:,k], \n",
    "                                                            tau= mycebmf.tau,\n",
    "                                                            has_nan=mycebmf.has_nan)\n",
    " \n",
    "betahat   =lhat\n",
    "sebetahat =s_l \n",
    "prior     = mycebmf.prior_L\n",
    "verbose=False\n",
    "mult=np.sqrt(2) \n",
    "\n",
    "\n",
    "\n",
    "np.isinf (lhat ).any()\n",
    "sebetahat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ash_obj = ash(betahat   =lhat,\n",
    "                      sebetahat =s_l ,\n",
    "                      prior     = mycebmf.prior_L,\n",
    "                      verbose=False\n",
    "                      )\n",
    "print(ash_obj.post_mean)\n",
    "mycebmf.L  [:,k] =ash_obj.post_mean\n",
    "mycebmf.L2 [:,k] =ash_obj.post_mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "mycebmf.cal_partial_residuals(k=k)\n",
    "\n",
    "fhat , s_f  = compute_hat_f_and_s_f(Z = mycebmf.Rk,\n",
    "                                                            nu = mycebmf.L[:,k] ,\n",
    "                                                            omega= mycebmf.L2[:,k], \n",
    "                                                            tau= mycebmf.tau,\n",
    "                                                            has_nan=mycebmf.has_nan)\n",
    "plt.scatter(s_f, fhat)\n",
    "\n",
    "ash_obj = ash(betahat   =fhat,\n",
    "                      sebetahat =s_f ,\n",
    "                      prior     = mycebmf.prior_F,\n",
    "                      verbose=False\n",
    "                      )\n",
    "print(ash_obj.scale)\n",
    "\n",
    "mycebmf.F  [:,k] =ash_obj.post_mean\n",
    "mycebmf.F2 [:,k] =ash_obj.post_mean2\n",
    "print(ash_obj.log_lik2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat   =fhat \n",
    "sebetahat =s_f  +1e-7\n",
    "prior     = mycebmf.prior_F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=autoselect_scales_mix_exp(betahat  = betahat,\n",
    "                                         sebetahat= sebetahat,\n",
    "                                          mult=np.sqrt(2))\n",
    "\n",
    "L= get_data_loglik_exp(betahat=betahat ,\n",
    "                                 sebetahat=sebetahat , \n",
    "                                 scale=scale)\n",
    "optimal_pi = optimize_pi( np.exp(L),\n",
    "                                 penalty=10,\n",
    "                                 verbose=True)  \n",
    "log_pi=  np.tile(np.log(optimal_pi+1e-32), (betahat.shape[0],1))\n",
    "        \n",
    "out= posterior_mean_exp(betahat, sebetahat,\n",
    "                                 log_pi=log_pi, \n",
    "                                 scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_pi\n",
    "plt.scatter(optimal_pi, range(optimal_pi.shape[0]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fhat,out.post_mean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=autoselect_scales_mix_exp(betahat  = betahat,\n",
    "                                         sebetahat= sebetahat,\n",
    "                                          mult=np.sqrt(2))\n",
    "L= get_data_loglik_exp(betahat=betahat ,\n",
    "                                 sebetahat=sebetahat , \n",
    "                                 scale=scale)\n",
    "optimal_pi = optimize_pi( np.exp(L),\n",
    "                                 penalty=penalty,\n",
    "                                 verbose=verbose)  \n",
    "log_pi=  np.tile(np.log(optimal_pi+1e-32), (betahat.shape[0],1))\n",
    "        \n",
    "out= posterior_mean_exp(betahat, sebetahat,\n",
    "                                 log_pi=log_pi, \n",
    "                                 scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmaamax  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_f=1e-8+s_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat   =lhat\n",
    "sebetahat =s_l \n",
    "prior     = mycebmf.prior_L\n",
    "verbose=False\n",
    "mult=np.sqrt(2)\n",
    "\n",
    "plt.scatter(betahat, sebetahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(1e-32)\n",
    " \n",
    "plt.scatter(betahat,np.log(sebetahat))\n",
    "plt.axvline(x=0, color='red', linestyle='--')  # Add a horizontal line at y=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ash_obj.post_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(s_f, fhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=autoselect_scales_mix_exp(betahat  = betahat,\n",
    "                                         sebetahat= sebetahat,\n",
    "                                          mult=1.5)\n",
    "print(scale)\n",
    "L= get_data_loglik_exp(betahat=betahat ,\n",
    "                                 sebetahat=sebetahat , \n",
    "                                 scale=scale)\n",
    "optimal_pi = optimize_pi( np.exp(L),\n",
    "                                 penalty=10,\n",
    "                                 verbose=verbose)  \n",
    "print((L[5,:]))\n",
    "sebetahat[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycebmf.Rk[5,:]\n",
    "np.isnan(mycebmf.Rk[5,:]).sum()\n",
    "mycebmf.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pi=  np.tile(np.log(optimal_pi+1e-32), (betahat.shape[0],1))\n",
    "        \n",
    "out= posterior_mean_exp(betahat, sebetahat,\n",
    "                                 log_pi=log_pi, \n",
    "                                 scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sebetahat = sebetahat[betahat == 0]\n",
    "subset_sebetahat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = mycebmf.Rk\n",
    "nu = mycebmf.F[:,k] \n",
    "omega= mycebmf.F2[:,k]\n",
    "tau= mycebmf.tau\n",
    "has_nan=mycebmf.has_nan\n",
    " \n",
    "numerator_l_hat = np.sum(tau * Z * nu, axis=1)\n",
    "denominator_l_hat = np.sum(tau * omega, axis=1) + 1e-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator_l_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
