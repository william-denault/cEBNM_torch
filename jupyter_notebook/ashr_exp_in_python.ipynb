{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the path to utils.py\n",
    "sys.path.append(r\"c:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\")\n",
    "from distribution_operation import *\n",
    "from utils import *\n",
    "from numerical_routine import *\n",
    "from posterior_computation import *\n",
    "from ash import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat=  np.array([1,2,3,4,5])\n",
    "sebetahat=np.array([1,0.4,5,1,1])\n",
    "\n",
    "res= ash(betahat, sebetahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_val1=  np.random.normal(loc=0, scale=2, size=100)\n",
    "true_val0=  np.zeros( 100)\n",
    "\n",
    "observations_mu_1 =true_val1+np.random.normal(loc=0, scale=1, size=100)\n",
    "observations_mu_0 =true_val0+ np.random.normal(loc=0, scale=1, size=100)\n",
    "# Combine them into one array\n",
    "betahat = np.hstack([observations_mu_1, observations_mu_0])\n",
    "sebetahat=  np.repeat(1, betahat.shape[0])\n",
    "mult=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.09655728 0.14483592 0.21725389 0.32588083 0.48882124\n",
      " 0.73323186 1.0998478  1.64977169 2.47465754 3.71198631 5.56797947\n",
      " 8.35196921]\n",
      "[[-11.1798278  -11.54713595 -11.69181315 ... -14.09938759 -14.48735345\n",
      "  -14.88099136]\n",
      " [ -2.26779883  -2.42183393  -2.49445645 ...  -4.41027017  -4.78080513\n",
      "   -5.16242416]\n",
      " [ -0.94367937  -0.97367464  -0.99419138 ...  -2.38198105  -2.72857286\n",
      "   -3.09352021]\n",
      " ...\n",
      " [ -1.00184459  -1.04886194  -1.07705079 ...  -2.55455655  -2.90550089\n",
      "   -3.2734842 ]\n",
      " [ -1.00510704  -1.05284908  -1.08136066 ...  -2.56254128  -2.91366188\n",
      "   -3.28176812]\n",
      " [ -1.1343031   -1.20382845  -1.24189583 ...  -2.82837657  -3.1844733\n",
      "   -3.55604893]]\n",
      "[8.86530356e-01 3.77859403e-05 3.53566201e-06 2.83843077e-07\n",
      " 3.01635629e-08 1.33425650e-08 1.49869927e-07 5.75266292e-05\n",
      " 2.67575983e-02 8.65352758e-02 7.74445872e-05 1.33821789e-11\n",
      " 1.06241438e-18]\n",
      "(13,)\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m optimal_pi \u001b[38;5;241m=\u001b[39m optimize_pi( np\u001b[38;5;241m.\u001b[39mexp(L),\n\u001b[0;32m     10\u001b[0m                                  penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     11\u001b[0m                                  verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(optimal_pi)\n\u001b[1;32m---> 13\u001b[0m out\u001b[38;5;241m=\u001b[39m posterior_mean_exp(betahat, sebetahat,\n\u001b[0;32m     14\u001b[0m                                  log_pi\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(optimal_pi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-32\u001b[39m), \n\u001b[0;32m     15\u001b[0m                                  scale\u001b[38;5;241m=\u001b[39mscale)\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\posterior_computation.py:24\u001b[0m, in \u001b[0;36mposterior_mean_exp\u001b[1;34m(betahat, sebetahat, log_pi, scale)\u001b[0m\n\u001b[0;32m     22\u001b[0m assignment \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(log_pi)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(assignment\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 24\u001b[0m assignment \u001b[38;5;241m=\u001b[39m assignment \u001b[38;5;241m/\u001b[39m assignment\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     26\u001b[0m post_assign \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((betahat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], scale\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\conda_env\\ml\\Lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "scale=autoselect_scales_mix_exp(betahat  = betahat,\n",
    "                                         sebetahat= sebetahat,\n",
    "                                          mult=mult)\n",
    "print(scale)\n",
    "L= get_data_loglik_exp(betahat=betahat ,\n",
    "                                 sebetahat=sebetahat , \n",
    "                                 scale=scale)\n",
    "print(L)\n",
    "optimal_pi = optimize_pi( np.exp(L),\n",
    "                                 penalty=10,\n",
    "                                 verbose=True)  \n",
    "print(optimal_pi)\n",
    "out= posterior_mean_exp(betahat, sebetahat,\n",
    "                                 log_pi=np.log(optimal_pi+1e-32), \n",
    "                                 scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res\u001b[38;5;241m=\u001b[39m ash(betahat, sebetahat, prior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mpi)\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\ash.py:48\u001b[0m, in \u001b[0;36mash\u001b[1;34m(betahat, sebetahat, prior, mult, penalty, verbose)\u001b[0m\n\u001b[0;32m     42\u001b[0m     L\u001b[38;5;241m=\u001b[39m get_data_loglik_exp(betahat\u001b[38;5;241m=\u001b[39mbetahat ,\n\u001b[0;32m     43\u001b[0m                              sebetahat\u001b[38;5;241m=\u001b[39msebetahat , \n\u001b[0;32m     44\u001b[0m                              scale\u001b[38;5;241m=\u001b[39mscale)\n\u001b[0;32m     45\u001b[0m     optimal_pi \u001b[38;5;241m=\u001b[39m optimize_pi( np\u001b[38;5;241m.\u001b[39mexp(L),\n\u001b[0;32m     46\u001b[0m                              penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[0;32m     47\u001b[0m                              verbose\u001b[38;5;241m=\u001b[39mverbose)  \n\u001b[1;32m---> 48\u001b[0m     out\u001b[38;5;241m=\u001b[39m posterior_mean_exp(betahat, sebetahat,\n\u001b[0;32m     49\u001b[0m                              log_pi\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(optimal_pi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-32\u001b[39m), \n\u001b[0;32m     50\u001b[0m                              scale\u001b[38;5;241m=\u001b[39mscale)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ash_object(post_mean  \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpost_mean,\n\u001b[0;32m     54\u001b[0m                   post_mean2 \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpost_mean2,\n\u001b[0;32m     55\u001b[0m                   post_sd    \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpost_sd,\n\u001b[0;32m     56\u001b[0m                   scale      \u001b[38;5;241m=\u001b[39m scale,\n\u001b[0;32m     57\u001b[0m                   pi         \u001b[38;5;241m=\u001b[39m optimal_pi,\n\u001b[0;32m     58\u001b[0m                   prior      \u001b[38;5;241m=\u001b[39m prior )\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\python_work\\cEBNM_torch\\py\\posterior_computation.py:23\u001b[0m, in \u001b[0;36mposterior_mean_exp\u001b[1;34m(betahat, sebetahat, log_pi, scale)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mposterior_mean_exp\u001b[39m(betahat, sebetahat, log_pi, scale):\n\u001b[0;32m     22\u001b[0m     assignment \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(log_pi)\n\u001b[1;32m---> 23\u001b[0m     assignment \u001b[38;5;241m=\u001b[39m assignment \u001b[38;5;241m/\u001b[39m assignment\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m     mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m     post_assign \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((betahat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], scale\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Document\\Serieux\\Travail\\conda_env\\ml\\Lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "res= ash(betahat, sebetahat, prior=\"exp\")\n",
    "print(res.pi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(betahat, res.post_mean  )\n",
    "plt.xlabel(\"observed values\")\n",
    "plt.plot(betahat, betahat, color='red', label='x = y')\n",
    "plt.axhline(y=0, color=\"black\")\n",
    "plt.ylabel(\"posterior mean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
