{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        pi = self.softmax(x)  # Ensures sum over m of pi_{im}(x) equals 1 and each pi_{im}(x) is positive\n",
    "        return pi\n",
    "\n",
    "class CustomLikelihoodLoss(nn.Module):\n",
    "    def __init__(self, L_im):\n",
    "        super(CustomLikelihoodLoss, self).__init__()\n",
    "        self.L_im = torch.tensor(L_im, dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, pi, x):\n",
    "        # pi has shape [batch_size, M]\n",
    "        # L_im has shape [batch_size, M]\n",
    "        \n",
    "        # Compute the sum over m\n",
    "        inner_sum = torch.sum(pi * self.L_im, dim=1)\n",
    "        \n",
    "        # Compute log and sum over i (batch)\n",
    "        log_likelihood = torch.sum(torch.log(inner_sum))\n",
    "        \n",
    "        # Return negative log-likelihood as we want to minimize\n",
    "        return -log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5  # This is M in your equation\n",
    "batch_size = 32\n",
    "np.random.seed(42)  \n",
    "# Generate dummy data\n",
    "X = torch.randn(batch_size, input_size)\n",
    "L_im = np.random.rand(batch_size, output_size)  # This would be your actual L_im values\n",
    "\n",
    "\n",
    "# Create model, loss function, and optimizer\n",
    "model = CustomNet(input_size, hidden_size, output_size)\n",
    "criterion = CustomLikelihoodLoss(L_im)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.8172e-01,  5.3189e-02, -2.1003e-01, -1.1114e+00,  3.1042e-01,\n",
      "          1.3549e-01, -2.1518e+00,  5.7190e-01, -1.0991e+00, -1.3666e+00],\n",
      "        [ 6.0167e-01,  8.6843e-02,  1.5716e+00, -1.6280e+00,  3.4600e-01,\n",
      "          1.3615e-02, -1.3548e+00, -6.0066e-01,  9.8071e-01, -1.6869e+00],\n",
      "        [ 1.8261e-01, -1.4915e+00,  1.7250e+00,  1.0730e+00,  1.5054e+00,\n",
      "         -1.9959e-01,  3.5851e-01,  4.4212e-01, -1.6967e-01,  6.0200e-01],\n",
      "        [ 1.6055e+00, -1.0208e-01,  5.5977e-01, -5.2612e-01,  7.0976e-01,\n",
      "          4.6681e-01,  1.6503e+00, -1.4819e+00, -1.0760e+00,  2.3462e+00],\n",
      "        [ 3.0298e-01,  3.6652e-01, -1.2854e+00,  1.9645e-01,  1.5433e+00,\n",
      "         -4.8312e-01, -2.4922e+00, -2.8766e-01,  4.0799e-01, -4.7732e-01],\n",
      "        [-3.7122e-01, -3.9824e-01, -1.5951e+00,  1.0349e+00, -3.5979e-01,\n",
      "         -5.4680e-01, -9.6843e-01, -2.3286e-01,  1.2434e+00, -1.4911e+00],\n",
      "        [-4.0563e-01,  2.2707e-01,  1.2148e+00,  3.3989e-01,  1.3016e-01,\n",
      "         -1.0328e+00,  1.9271e+00, -3.0742e-01,  1.4131e-02, -4.9886e-01],\n",
      "        [ 2.5453e+00, -7.1199e-01, -8.2491e-01,  8.1172e-01,  3.6521e-01,\n",
      "          4.1053e-01, -4.3747e-01, -2.0443e-01, -1.2545e-01, -3.1397e-01],\n",
      "        [ 6.9433e-02, -8.7339e-01, -9.0335e-01,  4.6602e-01,  1.5344e+00,\n",
      "          1.5333e+00, -1.3455e+00, -1.4833e-02, -1.8506e+00, -9.2959e-01],\n",
      "        [-9.1337e-01, -1.2008e+00,  2.0806e-01, -2.1153e+00, -2.8622e+00,\n",
      "         -8.7385e-01, -8.2290e-01,  3.4984e-02,  2.1994e+00,  2.4421e-01],\n",
      "        [ 1.1840e+00, -3.3742e-01,  1.5471e-02, -1.9017e+00,  8.0296e-01,\n",
      "         -1.4419e+00,  3.9395e-01, -1.9646e+00, -6.5165e-02, -1.3635e+00],\n",
      "        [ 3.4847e-01,  1.2181e+00,  1.1592e-01, -1.5925e+00,  3.2910e-01,\n",
      "         -1.2447e+00,  1.0299e-01,  3.0143e-01, -5.1843e-01,  4.3241e-02],\n",
      "        [ 2.3202e+00, -6.8460e-01, -3.3141e-01, -8.6516e-02,  4.9512e-01,\n",
      "          4.1192e-01, -2.3711e-02,  5.3095e-01, -1.3963e+00, -6.6278e-01],\n",
      "        [ 8.7398e-01, -5.9201e-01, -1.3608e+00,  1.1249e+00, -5.9039e-01,\n",
      "         -5.4609e-01,  1.1790e+00, -4.2857e-01,  2.7908e-01,  1.2783e+00],\n",
      "        [ 8.9792e-01, -7.8176e-01,  3.0376e-01,  1.4223e+00, -2.2812e-01,\n",
      "          1.2007e+00,  6.5542e-01,  2.1102e+00, -3.3413e-01, -1.0270e+00],\n",
      "        [ 2.5701e-01, -7.1157e-01, -6.0789e-01, -2.0697e-01,  1.2226e+00,\n",
      "         -8.1559e-01,  4.6881e-01,  2.4670e-01, -1.2324e+00,  1.1597e+00],\n",
      "        [ 1.4612e+00,  3.3506e-01,  6.5438e-01,  4.3147e-01,  1.3371e-02,\n",
      "          1.0174e+00, -4.9055e-02,  1.4208e-01, -2.2234e+00, -1.0007e+00],\n",
      "        [-1.2054e+00,  5.7745e-01,  9.1695e-02, -5.2913e-01, -2.5368e+00,\n",
      "          6.7009e-01,  7.4715e-01,  3.2194e+00,  3.1442e-02,  3.6734e-01],\n",
      "        [-1.0033e+00,  8.1436e-02, -1.3347e-01,  1.0133e-01, -1.5766e-01,\n",
      "          1.3308e+00, -4.2997e-01,  1.0695e-01, -1.7781e-01,  3.9682e-01],\n",
      "        [-2.5101e-01,  4.7644e-01, -2.0618e+00,  5.3647e-01,  8.0349e-01,\n",
      "          1.2672e+00,  8.0209e-01, -2.1277e+00, -3.4589e-01,  2.9983e-01],\n",
      "        [ 9.8129e-01,  1.4168e+00, -1.0506e+00,  1.0930e+00,  3.2947e-01,\n",
      "          6.8814e-01, -5.1995e-01,  9.0699e-01, -1.4670e-01, -2.5160e-02],\n",
      "        [ 1.1302e+00, -4.3633e-01,  3.9350e-01, -2.8567e-01, -1.8941e+00,\n",
      "         -2.1960e-01, -3.4092e-02, -1.2490e-01,  4.5789e-02,  1.1545e+00],\n",
      "        [-1.6305e+00,  5.3758e-01,  9.2257e-01,  2.1899e+00, -3.0911e-01,\n",
      "         -8.1222e-02, -6.0517e-01,  5.5612e-01,  5.7667e-01,  2.2436e-01],\n",
      "        [ 1.0921e+00,  8.0660e-01,  1.0496e-01, -2.5449e-01,  7.7003e-01,\n",
      "          1.0161e+00,  1.6649e+00,  8.3409e-01, -8.3681e-01,  6.5093e-01],\n",
      "        [ 1.6215e-01, -4.7473e-01,  1.6185e+00, -3.2669e-01,  7.2394e-01,\n",
      "          4.6417e-01, -4.3885e-01,  1.6173e+00,  1.7757e+00,  6.5114e-01],\n",
      "        [-1.0667e-01, -9.1929e-01, -5.2402e-01,  2.5081e-01,  3.6616e-01,\n",
      "          1.9350e+00,  1.8954e-01, -1.0137e-01,  1.6317e-01,  7.6564e-01],\n",
      "        [ 1.3939e-01, -3.5200e-01,  1.3542e+00, -1.0205e-01,  1.6571e+00,\n",
      "          8.5691e-03,  5.5973e-01,  3.1895e-01,  7.8371e-01, -1.8105e-01],\n",
      "        [ 7.5475e-01,  9.2867e-02, -1.5510e+00, -4.0665e-01,  1.8100e+00,\n",
      "         -5.3249e-01,  4.8002e-02,  3.7924e-02,  9.3320e-01,  9.9099e-01],\n",
      "        [-1.0493e+00, -1.3757e+00, -3.5331e-01,  2.4173e-03,  2.8545e-01,\n",
      "          1.4030e+00, -1.4032e-01, -2.0685e-01, -7.3070e-01, -8.8518e-02],\n",
      "        [ 5.7580e-01, -1.6322e-01, -6.1658e-01,  2.2333e-02,  1.7121e-01,\n",
      "         -4.5659e-02, -3.3952e-01, -7.8458e-03, -1.8268e+00, -1.1008e+00],\n",
      "        [-7.5125e-01,  9.6126e-01, -9.0400e-01, -5.3995e-01, -9.8081e-01,\n",
      "         -9.1142e-01, -3.0670e-01,  8.4161e-01, -1.2438e+00, -1.2725e+00],\n",
      "        [-7.0168e-01,  1.1146e+00,  4.0255e-01, -2.4908e-01, -9.7821e-01,\n",
      "          4.7830e-01,  6.6132e-01, -4.6639e-02,  9.5961e-01, -3.0054e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.95071431 0.73199394 0.59865848 0.15601864]\n",
      " [0.15599452 0.05808361 0.86617615 0.60111501 0.70807258]\n",
      " [0.02058449 0.96990985 0.83244264 0.21233911 0.18182497]\n",
      " [0.18340451 0.30424224 0.52475643 0.43194502 0.29122914]\n",
      " [0.61185289 0.13949386 0.29214465 0.36636184 0.45606998]\n",
      " [0.78517596 0.19967378 0.51423444 0.59241457 0.04645041]\n",
      " [0.60754485 0.17052412 0.06505159 0.94888554 0.96563203]\n",
      " [0.80839735 0.30461377 0.09767211 0.68423303 0.44015249]\n",
      " [0.12203823 0.49517691 0.03438852 0.9093204  0.25877998]\n",
      " [0.66252228 0.31171108 0.52006802 0.54671028 0.18485446]\n",
      " [0.96958463 0.77513282 0.93949894 0.89482735 0.59789998]\n",
      " [0.92187424 0.0884925  0.19598286 0.04522729 0.32533033]\n",
      " [0.38867729 0.27134903 0.82873751 0.35675333 0.28093451]\n",
      " [0.54269608 0.14092422 0.80219698 0.07455064 0.98688694]\n",
      " [0.77224477 0.19871568 0.00552212 0.81546143 0.70685734]\n",
      " [0.72900717 0.77127035 0.07404465 0.35846573 0.11586906]\n",
      " [0.86310343 0.62329813 0.33089802 0.06355835 0.31098232]\n",
      " [0.32518332 0.72960618 0.63755747 0.88721274 0.47221493]\n",
      " [0.11959425 0.71324479 0.76078505 0.5612772  0.77096718]\n",
      " [0.4937956  0.52273283 0.42754102 0.02541913 0.10789143]\n",
      " [0.03142919 0.63641041 0.31435598 0.50857069 0.90756647]\n",
      " [0.24929223 0.41038292 0.75555114 0.22879817 0.07697991]\n",
      " [0.28975145 0.16122129 0.92969765 0.80812038 0.63340376]\n",
      " [0.87146059 0.80367208 0.18657006 0.892559   0.53934224]\n",
      " [0.80744016 0.8960913  0.31800347 0.11005192 0.22793516]\n",
      " [0.42710779 0.81801477 0.86073058 0.00695213 0.5107473 ]\n",
      " [0.417411   0.22210781 0.11986537 0.33761517 0.9429097 ]\n",
      " [0.32320293 0.51879062 0.70301896 0.3636296  0.97178208]\n",
      " [0.96244729 0.2517823  0.49724851 0.30087831 0.28484049]\n",
      " [0.03688695 0.60956433 0.50267902 0.05147875 0.27864646]\n",
      " [0.90826589 0.23956189 0.14489487 0.48945276 0.98565045]\n",
      " [0.24205527 0.67213555 0.76161962 0.23763754 0.72821635]]\n"
     ]
    }
   ],
   "source": [
    "print(L_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 21.1211\n",
      "Epoch [20/100], Loss: 17.3898\n",
      "Epoch [30/100], Loss: 13.8663\n",
      "Epoch [40/100], Loss: 11.2373\n",
      "Epoch [50/100], Loss: 9.9291\n",
      "Epoch [60/100], Loss: 9.0841\n",
      "Epoch [70/100], Loss: 8.7452\n",
      "Epoch [80/100], Loss: 8.5897\n",
      "Epoch [90/100], Loss: 8.3875\n",
      "Epoch [100/100], Loss: 8.3368\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    pi = model(X)\n",
    "    loss = criterion(pi, X)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitted pi values for each row of L_im:\n",
      "Row 1:\n",
      "L_im: [0.37454012 0.95071431 0.73199394 0.59865848 0.15601864]\n",
      "Fitted pi: [3.1463206e-03 9.9523711e-01 1.4966888e-03 8.5036416e-05 3.4706241e-05]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 2:\n",
      "L_im: [0.15599452 0.05808361 0.86617615 0.60111501 0.70807258]\n",
      "Fitted pi: [1.1397196e-03 3.5853568e-04 9.9848652e-01 1.0370062e-05 4.8927418e-06]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 3:\n",
      "L_im: [0.02058449 0.96990985 0.83244264 0.21233911 0.18182497]\n",
      "Fitted pi: [1.6097986e-04 9.9163967e-01 4.4779363e-04 1.7617054e-05 7.7339378e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 4:\n",
      "L_im: [0.18340451 0.30424224 0.52475643 0.43194502 0.29122914]\n",
      "Fitted pi: [2.3987794e-03 1.1582412e-04 9.9743098e-01 1.8259969e-07 5.4241842e-05]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 5:\n",
      "L_im: [0.61185289 0.13949386 0.29214465 0.36636184 0.45606998]\n",
      "Fitted pi: [9.9214184e-01 3.7237371e-03 1.3143159e-05 3.2847980e-05 4.0884828e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 6:\n",
      "L_im: [0.78517596 0.19967378 0.51423444 0.59241457 0.04645041]\n",
      "Fitted pi: [9.9812227e-01 1.5631468e-06 1.6827480e-05 1.6058035e-06 1.8578486e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 7:\n",
      "L_im: [0.60754485 0.17052412 0.06505159 0.94888554 0.96563203]\n",
      "Fitted pi: [6.2040323e-03 2.6723460e-04 3.9094062e-05 1.9135541e-05 9.9347055e-01]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 8:\n",
      "L_im: [0.80839735 0.30461377 0.09767211 0.68423303 0.44015249]\n",
      "Fitted pi: [9.9378681e-01 1.2565930e-03 2.9915893e-03 8.9598958e-05 1.8754241e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 9:\n",
      "L_im: [0.12203823 0.49517691 0.03438852 0.9093204  0.25877998]\n",
      "Fitted pi: [5.1924521e-03 9.9480397e-01 1.0218768e-06 1.6207258e-06 8.5645559e-07]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 10:\n",
      "L_im: [0.66252228 0.31171108 0.52006802 0.54671028 0.18485446]\n",
      "Fitted pi: [3.8743585e-07 3.0041340e-07 9.9999928e-01 3.2797944e-09 5.6626659e-09]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 11:\n",
      "L_im: [0.96958463 0.77513282 0.93949894 0.89482735 0.59789998]\n",
      "Fitted pi: [9.9941444e-01 2.6652864e-05 4.8146097e-04 1.9190043e-06 7.5515978e-05]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 12:\n",
      "L_im: [0.92187424 0.0884925  0.19598286 0.04522729 0.32533033]\n",
      "Fitted pi: [9.9617213e-01 1.2575656e-04 1.8162648e-04 3.3743527e-05 3.4868710e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 13:\n",
      "L_im: [0.38867729 0.27134903 0.82873751 0.35675333 0.28093451]\n",
      "Fitted pi: [9.7266269e-01 2.1215081e-02 5.9078829e-03 1.1788179e-04 9.6368050e-05]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 14:\n",
      "L_im: [0.54269608 0.14092422 0.80219698 0.07455064 0.98688694]\n",
      "Fitted pi: [6.9845113e-04 1.2187623e-04 6.6761910e-03 4.3927334e-06 9.9249905e-01]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 15:\n",
      "L_im: [0.77224477 0.19871568 0.00552212 0.81546143 0.70685734]\n",
      "Fitted pi: [9.7928911e-01 4.4592889e-04 2.9235528e-04 4.4646973e-04 1.9526217e-02]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 16:\n",
      "L_im: [0.72900717 0.77127035 0.07404465 0.35846573 0.11586906]\n",
      "Fitted pi: [6.3626650e-03 9.9146664e-01 1.6954707e-04 6.6472312e-05 1.9347148e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 17:\n",
      "L_im: [0.86310343 0.62329813 0.33089802 0.06355835 0.31098232]\n",
      "Fitted pi: [9.8609561e-01 1.1294730e-02 2.5275131e-03 5.4262127e-05 2.7829012e-05]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 18:\n",
      "L_im: [0.32518332 0.72960618 0.63755747 0.88721274 0.47221493]\n",
      "Fitted pi: [1.5475908e-03 5.2508603e-05 9.9837214e-01 1.0808207e-05 1.7056122e-05]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 19:\n",
      "L_im: [0.11959425 0.71324479 0.76078505 0.5612772  0.77096718]\n",
      "Fitted pi: [2.4525130e-03 1.6737251e-03 9.9554718e-01 1.1213601e-04 2.1442055e-04]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 20:\n",
      "L_im: [0.4937956  0.52273283 0.42754102 0.02541913 0.10789143]\n",
      "Fitted pi: [9.9327868e-01 6.5326030e-06 9.0467336e-04 9.3898956e-07 5.8092042e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 21:\n",
      "L_im: [0.03142919 0.63641041 0.31435598 0.50857069 0.90756647]\n",
      "Fitted pi: [3.0168022e-03 2.9019456e-04 1.0379563e-04 9.3050061e-05 9.9649614e-01]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 22:\n",
      "L_im: [0.24929223 0.41038292 0.75555114 0.22879817 0.07697991]\n",
      "Fitted pi: [4.7774891e-05 2.4387009e-06 9.9994898e-01 2.5528024e-07 5.6471413e-07]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 23:\n",
      "L_im: [0.28975145 0.16122129 0.92969765 0.80812038 0.63340376]\n",
      "Fitted pi: [4.4476817e-04 5.5804517e-04 9.9696487e-01 4.2534197e-05 1.9897458e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 24:\n",
      "L_im: [0.87146059 0.80367208 0.18657006 0.892559   0.53934224]\n",
      "Fitted pi: [9.8748720e-01 3.1039130e-05 8.2587346e-04 1.9078136e-05 1.1636690e-02]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 25:\n",
      "L_im: [0.80744016 0.8960913  0.31800347 0.11005192 0.22793516]\n",
      "Fitted pi: [2.0155927e-05 9.9142963e-01 6.7311558e-03 6.5059357e-05 1.7540272e-03]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 26:\n",
      "L_im: [0.42710779 0.81801477 0.86073058 0.00695213 0.5107473 ]\n",
      "Fitted pi: [3.4323726e-02 1.2801081e-03 9.6361369e-01 2.1521846e-05 7.6104118e-04]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 27:\n",
      "L_im: [0.417411   0.22210781 0.11986537 0.33761517 0.9429097 ]\n",
      "Fitted pi: [1.2584731e-03 7.8664897e-03 6.2023930e-05 7.6764467e-05 9.9073619e-01]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 28:\n",
      "L_im: [0.32320293 0.51879062 0.70301896 0.3636296  0.97178208]\n",
      "Fitted pi: [2.3557802e-03 6.0802478e-05 4.8495726e-06 1.8642144e-06 9.9757677e-01]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 29:\n",
      "L_im: [0.96244729 0.2517823  0.49724851 0.30087831 0.28484049]\n",
      "Fitted pi: [9.7311294e-01 8.9694224e-03 1.7794263e-02 7.8641111e-05 4.4771659e-05]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 30:\n",
      "L_im: [0.03688695 0.60956433 0.50267902 0.05147875 0.27864646]\n",
      "Fitted pi: [1.4633125e-02 9.8507994e-01 1.4196396e-04 9.6987598e-05 4.7909201e-05]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 31:\n",
      "L_im: [0.90826589 0.23956189 0.14489487 0.48945276 0.98565045]\n",
      "Fitted pi: [9.8284507e-01 4.4211033e-03 1.1402555e-03 1.6249190e-04 1.1431125e-02]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Row 32:\n",
      "L_im: [0.24205527 0.67213555 0.76161962 0.23763754 0.72821635]\n",
      "Fitted pi: [1.6129382e-03 2.7634926e-05 9.9766737e-01 8.8853458e-06 6.8310497e-04]\n",
      "Sum of fitted pi: 1.0000\n",
      "\n",
      "Summary of fitted pi values:\n",
      "Mean: [3.7316960e-01 1.8793282e-01 2.8115568e-01 5.5443008e-05 1.5768644e-01]\n",
      "Min: [3.8743585e-07 3.0041340e-07 1.0218768e-06 3.2797944e-09 5.6626659e-09]\n",
      "Max: [9.9941444e-01 9.9523711e-01 9.9999928e-01 4.4646973e-04 9.9757677e-01]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    fitted_pi = model(X)\n",
    "    print(\"\\nFitted pi values for each row of L_im:\")\n",
    "    for i in range(batch_size):\n",
    "        print(f\"Row {i+1}:\")\n",
    "        print(f\"L_im: {L_im[i]}\")\n",
    "        print(f\"Fitted pi: {fitted_pi[i].numpy()}\")\n",
    "        print(f\"Sum of fitted pi: {fitted_pi[i].sum().item():.4f}\")\n",
    "        print()\n",
    "\n",
    "# Print a summary of pi values\n",
    "print(\"Summary of fitted pi values:\")\n",
    "print(f\"Mean: {fitted_pi.mean(dim=0).numpy()}\")\n",
    "print(f\"Min: {fitted_pi.min(dim=0)[0].numpy()}\")\n",
    "print(f\"Max: {fitted_pi.max(dim=0)[0].numpy()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1463e-03, 9.9524e-01, 1.4967e-03, 8.5036e-05, 3.4706e-05],\n",
       "        [1.1397e-03, 3.5854e-04, 9.9849e-01, 1.0370e-05, 4.8927e-06],\n",
       "        [1.6098e-04, 9.9164e-01, 4.4779e-04, 1.7617e-05, 7.7339e-03],\n",
       "        [2.3988e-03, 1.1582e-04, 9.9743e-01, 1.8260e-07, 5.4242e-05],\n",
       "        [9.9214e-01, 3.7237e-03, 1.3143e-05, 3.2848e-05, 4.0885e-03],\n",
       "        [9.9812e-01, 1.5631e-06, 1.6827e-05, 1.6058e-06, 1.8578e-03],\n",
       "        [6.2040e-03, 2.6723e-04, 3.9094e-05, 1.9136e-05, 9.9347e-01],\n",
       "        [9.9379e-01, 1.2566e-03, 2.9916e-03, 8.9599e-05, 1.8754e-03],\n",
       "        [5.1925e-03, 9.9480e-01, 1.0219e-06, 1.6207e-06, 8.5646e-07],\n",
       "        [3.8744e-07, 3.0041e-07, 1.0000e+00, 3.2798e-09, 5.6627e-09],\n",
       "        [9.9941e-01, 2.6653e-05, 4.8146e-04, 1.9190e-06, 7.5516e-05],\n",
       "        [9.9617e-01, 1.2576e-04, 1.8163e-04, 3.3744e-05, 3.4869e-03],\n",
       "        [9.7266e-01, 2.1215e-02, 5.9079e-03, 1.1788e-04, 9.6368e-05],\n",
       "        [6.9845e-04, 1.2188e-04, 6.6762e-03, 4.3927e-06, 9.9250e-01],\n",
       "        [9.7929e-01, 4.4593e-04, 2.9236e-04, 4.4647e-04, 1.9526e-02],\n",
       "        [6.3627e-03, 9.9147e-01, 1.6955e-04, 6.6472e-05, 1.9347e-03],\n",
       "        [9.8610e-01, 1.1295e-02, 2.5275e-03, 5.4262e-05, 2.7829e-05],\n",
       "        [1.5476e-03, 5.2509e-05, 9.9837e-01, 1.0808e-05, 1.7056e-05],\n",
       "        [2.4525e-03, 1.6737e-03, 9.9555e-01, 1.1214e-04, 2.1442e-04],\n",
       "        [9.9328e-01, 6.5326e-06, 9.0467e-04, 9.3899e-07, 5.8092e-03],\n",
       "        [3.0168e-03, 2.9019e-04, 1.0380e-04, 9.3050e-05, 9.9650e-01],\n",
       "        [4.7775e-05, 2.4387e-06, 9.9995e-01, 2.5528e-07, 5.6471e-07],\n",
       "        [4.4477e-04, 5.5805e-04, 9.9696e-01, 4.2534e-05, 1.9897e-03],\n",
       "        [9.8749e-01, 3.1039e-05, 8.2587e-04, 1.9078e-05, 1.1637e-02],\n",
       "        [2.0156e-05, 9.9143e-01, 6.7312e-03, 6.5059e-05, 1.7540e-03],\n",
       "        [3.4324e-02, 1.2801e-03, 9.6361e-01, 2.1522e-05, 7.6104e-04],\n",
       "        [1.2585e-03, 7.8665e-03, 6.2024e-05, 7.6764e-05, 9.9074e-01],\n",
       "        [2.3558e-03, 6.0802e-05, 4.8496e-06, 1.8642e-06, 9.9758e-01],\n",
       "        [9.7311e-01, 8.9694e-03, 1.7794e-02, 7.8641e-05, 4.4772e-05],\n",
       "        [1.4633e-02, 9.8508e-01, 1.4196e-04, 9.6988e-05, 4.7909e-05],\n",
       "        [9.8285e-01, 4.4211e-03, 1.1403e-03, 1.6249e-04, 1.1431e-02],\n",
       "        [1.6129e-03, 2.7635e-05, 9.9767e-01, 8.8853e-06, 6.8310e-04]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_pi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
