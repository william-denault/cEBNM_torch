{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, output_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc2 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc2(z))\n",
    "        return self.softmax(self.fc3(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Custom Likelihood Loss\n",
    "class CustomLikelihoodLoss(nn.Module):\n",
    "    def __init__(self, L_im):\n",
    "        super(CustomLikelihoodLoss, self).__init__()\n",
    "        self.L_im = torch.tensor(L_im, dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, pi, mu, logvar):\n",
    "        # Reconstruction loss (negative log-likelihood)\n",
    "        inner_sum = torch.sum(pi * self.L_im, dim=1)\n",
    "        recon_loss = -torch.sum(torch.log(inner_sum))\n",
    "        \n",
    "        # KL divergence\n",
    "        kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        \n",
    "        return recon_loss + kl_div\n",
    "\n",
    "Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "data_loader = DataLoader(mnist_data, batch_size=128, shuffle=True)\n",
    "\n",
    "# Generate L_im (for demonstration, we'll use random values)\n",
    "L_im = np.random.rand(len(mnist_data), 10)  # 10 classes in MNIST\n",
    "\n",
    "# Initialize model and optimizer\n",
    "input_dim = 784  # 28x28 MNIST images\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "output_dim = 10  # 10 classes in MNIST\n",
    "\n",
    "model = VAE(input_dim, hidden_dim, latent_dim, output_dim)\n",
    "criterion = CustomLikelihoodLoss(L_im)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pi, mu, logvar = model(data)\n",
    "        loss = criterion(pi, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item() / len(data):.4f}')\n",
    "    \n",
    "    print(f'====> Epoch: {epoch+1} Average loss: {train_loss / len(data_loader.dataset):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print fitted pi for a few samples\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (data, _) in enumerate(data_loader):\n",
    "        if i >= 5:  # Print for 5 batches\n",
    "            break\n",
    "        pi, _, _ = model(data)\n",
    "        print(f\"\\nBatch {i+1}:\")\n",
    "        print(f\"Mean pi: {pi.mean(dim=0).numpy()}\")\n",
    "        print(f\"Min pi: {pi.min(dim=0)[0].numpy()}\")\n",
    "        print(f\"Max pi: {pi.max(dim=0)[0].numpy()}\")\n",
    "        print(f\"Sum of pi (should be close to 1): {pi.sum(dim=1).mean().item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstructions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_reconstructions(model, data, n=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pi, _, _ = model(data[:n])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n, figsize=(1.5*n, 3))\n",
    "    for i in range(n):\n",
    "        # Original\n",
    "        axes[0, i].imshow(data[i].squeeze(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Reconstruction (visualized as probabilities)\n",
    "        axes[1, i].imshow(pi[i].view(28, 28), cmap='viridis')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of test images\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Plot reconstructions\n",
    "plot_reconstructions(model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
