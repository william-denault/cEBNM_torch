{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f9b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from cebmf_torch import *\n",
    "from cebmf_torch.torch_utils import (\n",
    "    my_etruncnorm,\n",
    "    my_e2truncnorm,\n",
    "    logPhi,\n",
    "    _LOG_SQRT_2PI,\n",
    ")\n",
    "from cebmf_torch.torch_utils_mix import autoselect_scales_mix_exp\n",
    "import matplotlib.pyplot as plt\n",
    "from cebmf_torch.torch_ash import ash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529d64d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.48995049)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_etruncnorm(0,2,3,1).cpu().numpy() # should close to  1.48995049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61524fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.detach>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_etruncnorm(0,2,3,1).detach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2f08f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3934, dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_e2truncnorm(0,2,3,1) # should be close to, 2.39340536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c33322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat=  np.array([1,2,3,4,5], dtype=float)\n",
    "sebetahat=np.array([1,0.4,5,1,1], dtype=float)\n",
    "device = torch.device('cpu')\n",
    "scale = autoselect_scales_mix_exp ( torch.tensor(betahat),  torch.tensor(sebetahat)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38dea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat = torch.tensor([1.,2.,3.,4.,5.])\n",
    "sebetahat = torch.tensor([1.,0.4,5.,1.,1.])\n",
    "mult = torch.sqrt(torch.tensor(2.0)).item()\n",
    "res = ash(betahat, sebetahat, prior=\"exp\", mult=mult  , batch_size=5)\n",
    "expected_log_lik = -15.244064765169643\n",
    "expected_scale = np.array([ 0.        , 0.02929687, 0.04143204, 0.05859375, 0.08286408,\n",
    "                                0.1171875 , 0.16572815, 0.234375  , 0.3314563 , 0.46875   ,\n",
    "                                0.66291261, 0.9375    , 1.32582521, 1.875     , 2.65165043,\n",
    "                                3.75      , 5.30330086, 7.5       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6985f0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.244062423706055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d27cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0293, 0.0414, 0.0586, 0.0829, 0.1172, 0.1657, 0.2344, 0.3315,\n",
       "        0.4687, 0.6629, 0.9375, 1.3258, 1.8750, 2.6517, 3.7500, 5.3033, 7.5000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f331b61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data_loglik_exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m x\u001b[38;5;241m=\u001b[39mbetahat[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m s\u001b[38;5;241m=\u001b[39msebetahat[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m obs_wpost\u001b[38;5;241m=\u001b[39m \u001b[43mwpost_exp\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m expected_wpost\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m3.53987758e-06\u001b[39m, \u001b[38;5;241m6.61493885e-06\u001b[39m, \u001b[38;5;241m1.06391083e-05\u001b[39m, \u001b[38;5;241m2.86976960e-05\u001b[39m,\n\u001b[0;32m     12\u001b[0m        \u001b[38;5;241m1.69165759e-04\u001b[39m, \u001b[38;5;241m1.40776600e-03\u001b[39m, \u001b[38;5;241m8.91255655e-03\u001b[39m, \u001b[38;5;241m3.45101678e-02\u001b[39m,\n\u001b[0;32m     13\u001b[0m        \u001b[38;5;241m8.34205613e-02\u001b[39m, \u001b[38;5;241m1.38160703e-01\u001b[39m, \u001b[38;5;241m1.72844260e-01\u001b[39m, \u001b[38;5;241m1.77093219e-01\u001b[39m,\n\u001b[0;32m     14\u001b[0m        \u001b[38;5;241m1.57939387e-01\u001b[39m, \u001b[38;5;241m1.28091688e-01\u001b[39m, \u001b[38;5;241m9.74010338e-02\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Compute posteriors and truncated-moment means\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Note: first column is spike at 0; skip in expectation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m, in \u001b[0;36mwpost_exp\u001b[1;34m(x, s, w, scale)\u001b[0m\n\u001b[0;32m     25\u001b[0m se \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([s], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     26\u001b[0m sc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(scale, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 27\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_loglik_exp\u001b[49m(betahat, se, sc)  \u001b[38;5;66;03m# (1,K)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m logw \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mtensor(w, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m     29\u001b[0m log_post \u001b[38;5;241m=\u001b[39m L \u001b[38;5;241m+\u001b[39m logw\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data_loglik_exp' is not defined"
     ]
    }
   ],
   "source": [
    "non_informativ = np.full( scale.shape[0], 1/ scale.shape[0])\n",
    "n=betahat.shape[0]\n",
    "log_pi =  np.log( np.tile(non_informativ, (n, 1)))\n",
    "assignment = np.exp(log_pi)[0]\n",
    "assignment = assignment /   sum(assignment)\n",
    "w=assignment\n",
    "x=betahat[1]\n",
    "s=sebetahat[1]\n",
    "\n",
    "obs_wpost= wpost_exp ( x, s, w, scale)\n",
    "expected_wpost=np.array([3.53987758e-06, 6.61493885e-06, 1.06391083e-05, 2.86976960e-05,\n",
    "       1.69165759e-04, 1.40776600e-03, 8.91255655e-03, 3.45101678e-02,\n",
    "       8.34205613e-02, 1.38160703e-01, 1.72844260e-01, 1.77093219e-01,\n",
    "       1.57939387e-01, 1.28091688e-01, 9.74010338e-02])\n",
    "# Compute posteriors and truncated-moment means\n",
    "    # Note: first column is spike at 0; skip in expectation\n",
    "post_assign =   np.zeros ( (betahat.shape[0], scale.shape[0]))\n",
    "for i in range(betahat.shape[0]):\n",
    "        post_assign[i,] = wpost_exp ( x=betahat[i], s=sebetahat[i], w=np.exp(log_pi)[i,], scale=scale) \n",
    "\n",
    "post_mean = np.zeros(betahat.shape[0])\n",
    "post_mean2 = np.zeros(betahat.shape[0])\n",
    "for i in range(post_mean.shape[0]):\n",
    "        mu_i = betahat[i] - sebetahat[i]**2 * (1/scale[1:])\n",
    "        ex = np.array([my_etruncnorm(0, np.inf, m, sebetahat[i]) for m in mu_i])\n",
    "        ex2 = np.array([my_e2truncnorm(0, 99999, m, sebetahat[i]) for m in mu_i])\n",
    "        post_mean[i]=  np.sum( post_assign[i,1:] * ex )\n",
    "        post_mean2[i] = np.sum( post_assign[i,1:] * ex2 )\n",
    "\n",
    "expected_post_mean= np.array([0.4836384 , 1.89328341, 1.05670973, 3.57009763, 4.66379651])\n",
    "expected_post_mean2= np.array([ 0.59674218,  3.75372025,  4.34337321, 13.89299102, 22.81107216])\n",
    "\n",
    "    # Use our get_data_loglik + softmax responsibilities in the same way\n",
    "bet = torch.tensor(betahat, dtype=torch.float64)\n",
    "se = torch.tensor(sebetahat, dtype=torch.float64)\n",
    "sc = torch.tensor(scale, dtype=torch.float64)\n",
    "L = get_data_loglik_exp(bet, se, sc)  # (n,K)\n",
    "post = torch.softmax(L + torch.log(torch.tensor(non_informativ, dtype=torch.float64)).view(1,-1), dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfa3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(obs_wpost, expected_wpost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter (post_mean, expected_post_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter (post_mean2, expected_post_mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a27a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
