{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9591091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Reproducibility\n",
    "import random\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from cebmf_torch import cEBMF\n",
    "#seed = 1234\n",
    "#random.seed(seed)\n",
    "#torch.manual_seed(seed)\n",
    "#if torch.cuda.is_available():\n",
    "#    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe2357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank-1 Matrix (Outer Product):\n",
      "[[0.28915743 0.09213396 0.35769013 ... 0.03979447 0.12895387 0.04006715]\n",
      " [0.48921275 0.15587741 0.60516022 ... 0.06732651 0.21817139 0.06778785]\n",
      " [0.5803861  0.18492789 0.71794241 ... 0.07987399 0.25883145 0.0804213 ]\n",
      " ...\n",
      " [0.53052616 0.16904106 0.65626525 ... 0.07301215 0.2365957  0.07351245]\n",
      " [0.29936931 0.09538777 0.37032231 ... 0.04119985 0.13350801 0.04148216]\n",
      " [0.49882973 0.15894166 0.61705651 ... 0.06865002 0.22246022 0.06912043]]\n",
      "\n",
      "Noisy Matrix (with Homoscedastic Noise):\n",
      "[[ 0.18715048  0.13683926  0.34348125 ... -0.00386853  0.19247289\n",
      "   0.07502474]\n",
      " [ 0.52193467  0.22771712  0.50512986 ...  0.17472207  0.19230235\n",
      "   0.26043551]\n",
      " [ 0.4785419   0.25428278  0.87488213 ... -0.02601621  0.38762804\n",
      "   0.12603815]\n",
      " ...\n",
      " [ 0.61109474  0.32999699  0.50051302 ...  0.0012181   0.30546258\n",
      "   0.18430159]\n",
      " [ 0.15930202 -0.00883887  0.33373319 ... -0.01966066  0.10964651\n",
      "  -0.09302696]\n",
      " [ 0.60016656  0.14030654  0.57636693 ...  0.04301479  0.24739849\n",
      "  -0.07843244]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---- Parameters\n",
    "n, p = 50, 40\n",
    "noise_std = 0.1\n",
    "\n",
    "# (Optional) choose device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---- Data generation (PyTorch)\n",
    "# Use float64 to mirror NumPy defaults\n",
    "u = torch.rand(n, dtype=torch.float64, device=device)          # length n\n",
    "v = torch.rand(p, dtype=torch.float64, device=device)          # length p\n",
    "\n",
    "# Rank-1 matrix via outer product\n",
    "rank_1_matrix = torch.outer(u, v)                              # (n, p)\n",
    "\n",
    "# Homoscedastic Gaussian noise\n",
    "noise = noise_std * torch.randn(n, p, dtype=torch.float64, device=device)\n",
    "\n",
    "noisy_matrix = rank_1_matrix + noise\n",
    "\n",
    "# ---- Print (move to CPU for readability if needed)\n",
    "print(\"Rank-1 Matrix (Outer Product):\")\n",
    "print(rank_1_matrix.cpu().numpy())\n",
    "\n",
    "print(\"\\nNoisy Matrix (with Homoscedastic Noise):\")\n",
    "print(noisy_matrix.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1d6e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1240, -0.2149, -0.0410, -0.3877, -0.2755,  0.2281, -0.1114, -0.3219,\n",
      "         0.2945, -0.1123, -0.1232,  0.1387,  0.0478, -0.2190,  0.0192, -0.0589,\n",
      "        -0.0051, -0.1646, -0.0535, -0.0666, -0.1248, -0.3188, -0.0734, -0.1220,\n",
      "         0.3127, -0.0605,  0.3836,  0.2007,  0.0073,  0.1812, -0.1719, -0.1172,\n",
      "         0.1402,  0.1460,  0.1394,  0.2210,  0.0938,  0.0174,  0.0573,  0.2568,\n",
      "         0.1158, -0.0293,  0.1898, -0.0880, -0.1410,  0.1319,  0.0541, -0.0869,\n",
      "         0.1575, -0.3047])\n",
      "tensor([-0.2431,  0.0227,  0.1310,  0.1155, -0.1013,  0.2668, -0.0760,  0.0736,\n",
      "         0.2138, -0.0299,  0.0891, -0.1209,  0.0914,  0.1256, -0.0154,  0.2726,\n",
      "         0.0953, -0.1832,  0.0556, -0.1858, -0.2996,  0.0595,  0.0110, -0.1911,\n",
      "         0.2050, -0.2289, -0.0930, -0.1708,  0.0639,  0.0008,  0.1237, -0.0474,\n",
      "        -0.2476, -0.0806, -0.1824,  0.2265,  0.1521,  0.0231, -0.3243, -0.0643])\n"
     ]
    }
   ],
   "source": [
    "mycebmf=  cEBMF(data= noisy_matrix) \n",
    "mycebmf.initialize()\n",
    "print(mycebmf.L[:,1])\n",
    "print(mycebmf.F[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5839eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycebmf.iter_once()\n",
    "mycebmf.update_fitted_value()\n",
    "import numpy as np\n",
    "K=0\n",
    "mycebmf.Y_fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddec261",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "\n",
    "Rk = self._partial_residual_masked(k)  # (N,P), zeros where missing\n",
    "fk = self.F[:, k]  # (P,)\n",
    "fk2 = self.F2[:, k]  # (P,)\n",
    "\n",
    "if tau_map is None:\n",
    "        denom_l = (\n",
    "                    (fk2.view(1, -1) * self.mask).sum(dim=1).clamp_min(eps)\n",
    "                )  # (N,)\n",
    "                num_l = Rk @ fk  # (N,)\n",
    "                se_l = torch.sqrt(1.0 / (self.tau * denom_l))\n",
    "    else:\n",
    "                denom_l = (\n",
    "                    (tau_map * (fk2.view(1, -1) * self.mask)).sum(dim=1).clamp_min(eps)\n",
    "                )  # (N,)\n",
    "                num_l = (tau_map * Rk) @ fk  # (N,)\n",
    "                se_l = torch.sqrt(1.0 / denom_l)\n",
    "\n",
    "            lhat = num_l / denom_l\n",
    "        # print(denom_l)\n",
    " \n",
    "X_model = self.update_cov_L(k)\n",
    "with torch.enable_grad():\n",
    "            resL = self.prior_L_fn(\n",
    "                X=X_model,\n",
    "                betahat=lhat,\n",
    "                sebetahat=se_l,\n",
    "                model_param=self.model_state_L[k],\n",
    "            )\n",
    "with torch.no_grad():\n",
    "            self.model_state_L[k] = resL.model_param\n",
    "            self.L[:, k] = resL.post_mean\n",
    "            self.L2[:, k] = resL.post_mean2\n",
    "            nm_ll_L = normal_means_loglik(\n",
    "                x=lhat, s=se_l, Et=resL.post_mean, Et2=resL.post_mean2\n",
    "            )\n",
    "            self.kl_l[k] = torch.as_tensor((-resL.loss) - nm_ll_L, device=self.device)\n",
    "            self.pi0_L[k] = resL.pi0_null if hasattr(resL, \"pi0_null\") else None\n",
    "\n",
    "            # ---------- Update F[:, k] ----------\n",
    "Rk = self._partial_residual_masked(k)  # recompute with updated L\n",
    "lk = self.L[:, k]  # (N,)\n",
    "lk2 = self.L2[:, k]  # (N,)\n",
    "\n",
    "if tau_map is None:\n",
    "                denom_f = (\n",
    "                    (lk2.view(-1, 1) * self.mask).sum(dim=0).clamp_min(eps)\n",
    "                )  # (P,)\n",
    "                num_f = Rk.T @ lk  # (P,)\n",
    "                se_f = torch.sqrt(1.0 / (self.tau * denom_f))\n",
    "else:\n",
    "                denom_f = (\n",
    "                    (tau_map * (lk2.view(-1, 1) * self.mask)).sum(dim=0).clamp_min(eps)\n",
    "                )  # (P,)\n",
    "                num_f = (tau_map * Rk).T @ lk  # (P,)\n",
    "                se_f = torch.sqrt(1.0 / denom_f)\n",
    "\n",
    "            fhat = num_f / denom_f\n",
    "\n",
    "X_model = self.update_cov_F(k)\n",
    "with torch.enable_grad():\n",
    "            resF = self.prior_F_fn(\n",
    "                X=X_model,\n",
    "                betahat=fhat,\n",
    "                sebetahat=se_f,\n",
    "                model_param=self.model_state_F[k],\n",
    "            )\n",
    "with torch.no_grad():\n",
    "            self.model_state_F[k] = resF.model_param\n",
    "            self.F[:, k] = resF.post_mean\n",
    "            self.F2[:, k] = resF.post_mean2\n",
    "            # store as scalar on device; PriorResult.loss already = -log_lik\n",
    "            nm_ll_F = normal_means_loglik(\n",
    "                x=fhat, s=se_f, Et=resF.post_mean, Et2=resF.post_mean2\n",
    "            )\n",
    "            self.kl_f[k] = torch.as_tensor((-resF.loss) - nm_ll_F, device=self.device)\n",
    "            self.pi0_F[k] = resF.pi0_null if hasattr(resF, \"pi0_null\") else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
