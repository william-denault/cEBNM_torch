{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b676aa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data_loglik_normal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m p\u001b[38;5;241m=\u001b[39m scale\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Single x=betahat[1]\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m L_single \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_loglik_normal\u001b[49m(torch\u001b[38;5;241m.\u001b[39mtensor([betahat[\u001b[38;5;241m1\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[0;32m     15\u001b[0m                                       torch\u001b[38;5;241m.\u001b[39mtensor([sebetahat[\u001b[38;5;241m1\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[0;32m     16\u001b[0m                                       torch\u001b[38;5;241m.\u001b[39mtensor(location, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[0;32m     17\u001b[0m                                       torch\u001b[38;5;241m.\u001b[39mtensor(scale, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64))\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m expected_scale\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.\u001b[39m        , \u001b[38;5;241m0.03827328\u001b[39m, \u001b[38;5;241m0.07654655\u001b[39m, \u001b[38;5;241m0.15309311\u001b[39m, \u001b[38;5;241m0.30618622\u001b[39m,\n\u001b[0;32m     20\u001b[0m        \u001b[38;5;241m0.61237244\u001b[39m, \u001b[38;5;241m1.22474487\u001b[39m, \u001b[38;5;241m2.44948974\u001b[39m, \u001b[38;5;241m4.89897949\u001b[39m, \u001b[38;5;241m9.79795897\u001b[39m])\n\u001b[0;32m     21\u001b[0m expected_convolved\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12.5026478\u001b[39m , \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12.39380192\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12.07903895\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10.97389398\u001b[39m,\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8.11500906\u001b[39m,  \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.34451202\u001b[39m,  \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.37716661\u001b[39m,  \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.15265225\u001b[39m,\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.59406918\u001b[39m,  \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3.22274394\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data_loglik_normal' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from cebmf_torch import *\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "betahat=  np.array([1,2,3,4,5], dtype=float)\n",
    "sebetahat=np.array([1,0.4,5,1,1], dtype=float)\n",
    "scale = autoselect_scales_mix_norm ( torch.tensor(betahat),  torch.tensor(sebetahat)).cpu().numpy()\n",
    "location = np.zeros_like(scale)\n",
    "n=betahat.shape[0]\n",
    "p= scale.shape[0]\n",
    "\n",
    "    # Single x=betahat[1]\n",
    "L_single = get_data_loglik_normal(torch.tensor([betahat[1]], dtype=torch.float64),\n",
    "                                      torch.tensor([sebetahat[1]], dtype=torch.float64),\n",
    "                                      torch.tensor(location, dtype=torch.float64),\n",
    "                                      torch.tensor(scale, dtype=torch.float64)).cpu().numpy()[0]\n",
    "\n",
    "expected_scale= np.array([0.        , 0.03827328, 0.07654655, 0.15309311, 0.30618622,\n",
    "       0.61237244, 1.22474487, 2.44948974, 4.89897949, 9.79795897])\n",
    "expected_convolved= np.array([-12.5026478 , -12.39380192, -12.07903895, -10.97389398,\n",
    "        -8.11500906,  -4.34451202,  -2.37716661,  -2.15265225,\n",
    "        -2.59406918,  -3.22274394])\n",
    "\n",
    "    # Full loglik matrix\n",
    "data_loglik = get_data_loglik_normal ( torch.tensor(betahat, dtype=torch.float64),\n",
    "                                           torch.tensor(sebetahat, dtype=torch.float64),\n",
    "                                           torch.zeros_like(torch.tensor(scale, dtype=torch.float64)),\n",
    "                                           torch.tensor(scale, dtype=torch.float64)).cpu().numpy()\n",
    "\n",
    "    # Apply log-sum-exp with uniform pi\n",
    "log_pi = np.log(np.full((n,p), 1/p))\n",
    "res = np.log(np.exp(data_loglik) * (1/p))\n",
    "\n",
    "    # Reproduce \"expected_result\" matrix using original constants for sanity\n",
    "expected_res= np.array([[ -2.0667347 ,  -2.06673523,  -2.06674321,  -2.06686784,\n",
    "         -2.06868363,  -2.08959792,  -2.22488006,  -2.61111834,\n",
    "         -3.19617261,  -3.85924482],\n",
    "       [-11.41455194, -11.30570607, -10.99094309,  -9.88579812,\n",
    "         -7.0269132 ,  -3.25641616,  -1.28907075,  -1.06455639,\n",
    "         -1.50597332,  -2.13464808],\n",
    "       [ -2.22020012,  -2.22021887,  -2.22027512,  -2.22050006,\n",
    "         -2.22139914,  -2.22498433,  -2.2391459 ,  -2.2929171 ,\n",
    "         -2.46850909,  -2.86584757],\n",
    "       [ -7.05746176,  -7.04649204,  -7.01378096,  -6.88583918,\n",
    "         -6.41655355,  -5.03487044,  -2.71560713,  -1.17327398,\n",
    "         -0.98689967,  -1.42729148],\n",
    "       [-11.22103348, -11.2034816 , -11.15113909, -10.94635747,\n",
    "        -10.19441099,  -7.97116944,  -4.17917885,  -1.47970284,\n",
    "         -0.83047139,  -1.13725495]])\n",
    "\n",
    "expected_loglik_mat= np.array([[ -1.41893853,  -1.41893907,  -1.41894705,  -1.41907168,\n",
    "         -1.42088747,  -1.44180176,  -1.5770839 ,  -1.96332218,\n",
    "         -2.54837645,  -3.21144866],\n",
    "       [-12.5026478 , -12.39380192, -12.07903895, -10.97389398,\n",
    "         -8.11500906,  -4.34451202,  -2.37716661,  -2.15265225,\n",
    "         -2.59406918,  -3.22274394],\n",
    "       [ -2.70837645,  -2.7083952 ,  -2.70845144,  -2.70867638,\n",
    "         -2.70957546,  -2.71316065,  -2.72732222,  -2.78109343,\n",
    "         -2.95668542,  -3.35402389],\n",
    "       [ -8.91893853,  -8.90796881,  -8.87525773,  -8.74731596,\n",
    "         -8.27803033,  -6.89634722,  -4.5770839 ,  -3.03475075,\n",
    "         -2.84837645,  -3.28876825],\n",
    "       [-13.41893853, -13.40138666, -13.34904414, -13.14426252,\n",
    "        -12.39231604, -10.16907449,  -6.3770839 ,  -3.67760789,\n",
    "         -3.02837645,  -3.33516   ]])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87384855",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(scale, expected_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(L_single, expected_convolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_loglik , expected_loglik_mat )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
